{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18f03e0a",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f98c2c",
   "metadata": {},
   "source": [
    "Por incompatibilidades entre librerias nos vemos obligados a hacer este workaround para que solucionar los problemas de dependencias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e43a3d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nicov\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_forecasting\\models\\base_model.py:30: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import  scipy.signal.signaltools\n",
    "import numpy as np\n",
    "\n",
    "def _centered(arr, newsize):\n",
    "    # Return the center newsize portion of the array.\n",
    "    newsize = np.asarray(newsize)\n",
    "    currsize = np.array(arr.shape)\n",
    "    startind = (currsize - newsize) // 2\n",
    "    endind = startind + newsize\n",
    "    myslice = [slice(startind[k], endind[k]) for k in range(len(endind))]\n",
    "    return arr[tuple(myslice)]\n",
    "\n",
    "scipy.signal.signaltools._centered = _centered\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# import os\n",
    "# import pickle\n",
    "import pytorch_forecasting\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters\n",
    "from pytorch_forecasting import TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from lightning.pytorch.callbacks import EarlyStopping, LearningRateMonitor\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "import torch\n",
    "from pytorch_forecasting.metrics import MAE, SMAPE, PoissonLoss, QuantileLoss, MAPE, MASE\n",
    "from lightning.pytorch.tuner import Tuner\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from  scipy.signal.signaltools import _centered\n",
    "from tft_helper import *\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "torch.backends.cudnn.benchmark = True # Enables cuDNN auto-tuner for faster runtime when input sizes are consistent\n",
    "\n",
    "basepath = os.path.abspath(\"\")  # script directory\n",
    "\n",
    "sys.path.insert(1, os.path.join(basepath, \"..\\\\\"))\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "018de99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install optuna==3.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf5d2e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82736cf5",
   "metadata": {},
   "source": [
    "# PARAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0f9f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_file = 'S&P500'\n",
    "exog_files = ['Nasdaq', 'IBEX35', 'EUStoxx50', 'DowJones', 'BTC', 'USD_EUR', 'GBP_USD', 'USTech100']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62f8001a",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "seq_len = 5 #sequence lenght: how many timesteps does a sequence have. For example a week could be considered a single sequence, therefore seq_len would be 5 as as the stock market opens 5 days a week.\n",
    "pred_len = 25 # prediction lenght: How many timesteps does a prediction sequence have. For example if each prediction is a full week pred_len should be 5 as the stock market opens 5 days a week.\n",
    "n_prev_len = 50 # Number of previous timesteps to take for inference. \n",
    "n_preds = 4 # number of predictions with test data\n",
    "test_len = pred_len * n_preds  # Number of timesteps to use for test data.\n",
    "group = \"group\" # If a same model should predict different stores, indices etc specify how to group them. If theres only one time series the set group col to one full of the same value.\n",
    "loss = QuantileLoss() # Loss function. \n",
    "epochs = 75 # Epochs to train the model.\n",
    "\n",
    "# Set ts date range\n",
    "date_start = '2010-01-04' #None #\"2023-06-01\"\n",
    "date_end = \"2024-7-29\"\n",
    "shift = 1 # How many times to shift values. Useful for using last indicator values (RSI, MACD...) for inference\n",
    "ts_indicator_params = {\n",
    "    \"moving_average_windows\": [5, 10, 20, 50, 100, 200], # Moving averages periods\n",
    "    \"sigma_gaussian_filter\": [1,2],\n",
    "    \"n_lags\": 10,\n",
    "                     \n",
    "                     }\n",
    "# cols_to_shift = [2:]\n",
    "\n",
    "# Set training config.\n",
    "lr_finder = False\n",
    "grid_search = \"random\"\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=10, verbose=False, mode=\"min\")\n",
    "lr_logger = LearningRateMonitor()  # log the learning rate\n",
    "# logger = TensorBoardLogger(\"lightning_logs\")  # logging results to a tensorboard\n",
    "\n",
    "# TFT training params.\n",
    "tft_params =  {\"gradient_clip_val\": 0.03, \"hidden_size\": 24, \"dropout\": 0.25, \"hidden_continuous_size\": 24, \"attention_head_size\": 4, \"learning_rate\": 0.01, \"loss\": loss, \"early_stop_callback\": early_stop_callback}\n",
    "\n",
    "\n",
    "PIB_relevant_countries = ['USA',\n",
    " 'CHN',\n",
    "#  'EMU',\n",
    " 'DEU',\n",
    "#  'FRA',\n",
    "#  'GBR',\n",
    " 'JPN',\n",
    " 'IND',\n",
    " 'BRA',\n",
    " 'CAN',\n",
    "#  'AUS',\n",
    "#  'ITA',\n",
    "#  'KOR',\n",
    "#  'MEX',\n",
    "#  'IDN',\n",
    "#  'SAU',\n",
    "#  'ZAF',\n",
    "#  'TUR',\n",
    "#  'ESP'\n",
    " ]\n",
    "\n",
    "# If grid search, set param grid.\n",
    "# param_grid = {\n",
    "#     \"gradient_clip_val\": [0.01, 0.03, 0.05],\n",
    "#     \"hidden_size\": [8, 16, 32],\n",
    "#     \"dropout\": [0.1, 0.25, 0.4],\n",
    "#     \"hidden_continuous_size\": [8, 16, 32],\n",
    "#     \"attention_head_size\": [2, 4, 8],\n",
    "#     \"learning_rate\": [0.005, 0.01, 0.03],\n",
    "#     \"loss\": [loss],\n",
    "#     \"test_len\": [test_len],\n",
    "#     \"pred_len\": [pred_len],\n",
    "#     \"n_prev_len\": [n_prev_len],\n",
    "# }\n",
    "\n",
    "param_grid = {\n",
    "    \"gradient_clip_val\": [0.01, 0.03, 0.05],\n",
    "    \"hidden_size\": [8, 16, 32],\n",
    "    \"dropout\": [0.1, 0.2, 0.3],\n",
    "    \"hidden_continuous_size\": [16, 64, 128],\n",
    "    \"attention_head_size\": [4,8,16],\n",
    "    \"learning_rate\": [0.005, 0.01, 0.03],\n",
    "    \"loss\": [loss],\n",
    "    \"test_len\": [test_len],\n",
    "    \"pred_len\": [pred_len],\n",
    "    \"n_prev_len\": [n_prev_len],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8032f7e1",
   "metadata": {
    "id": "8032f7e1"
   },
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8621112e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset does not contain volume data.\n",
      "Dataset does not contain volume data.\n"
     ]
    }
   ],
   "source": [
    "df = create_combined_ts_df(target_file, exog_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dee9c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>target</th>\n",
       "      <th>open</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>vol</th>\n",
       "      <th>var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>1886.7</td>\n",
       "      <td>1882.7</td>\n",
       "      <td>1890.0</td>\n",
       "      <td>1881.6</td>\n",
       "      <td>194040000.0</td>\n",
       "      <td>1.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>1888.4</td>\n",
       "      <td>1887.3</td>\n",
       "      <td>1891.3</td>\n",
       "      <td>1877.5</td>\n",
       "      <td>215840000.0</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-06</td>\n",
       "      <td>1878.4</td>\n",
       "      <td>1887.9</td>\n",
       "      <td>1893.2</td>\n",
       "      <td>1873.9</td>\n",
       "      <td>215110000.0</td>\n",
       "      <td>-0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-07</td>\n",
       "      <td>1876.7</td>\n",
       "      <td>1878.2</td>\n",
       "      <td>1881.3</td>\n",
       "      <td>1867.6</td>\n",
       "      <td>239020000.0</td>\n",
       "      <td>-0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-08</td>\n",
       "      <td>1892.6</td>\n",
       "      <td>1870.9</td>\n",
       "      <td>1893.3</td>\n",
       "      <td>1868.6</td>\n",
       "      <td>231540000.0</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4045</th>\n",
       "      <td>2024-11-24</td>\n",
       "      <td>20857.4</td>\n",
       "      <td>20856.5</td>\n",
       "      <td>20875.3</td>\n",
       "      <td>20851.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4046</th>\n",
       "      <td>2024-11-25</td>\n",
       "      <td>20762.4</td>\n",
       "      <td>20860.9</td>\n",
       "      <td>20998.5</td>\n",
       "      <td>20706.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4047</th>\n",
       "      <td>2024-11-26</td>\n",
       "      <td>20909.2</td>\n",
       "      <td>20760.2</td>\n",
       "      <td>20946.8</td>\n",
       "      <td>20682.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4048</th>\n",
       "      <td>2024-11-27</td>\n",
       "      <td>20759.0</td>\n",
       "      <td>20911.8</td>\n",
       "      <td>20939.9</td>\n",
       "      <td>20612.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4049</th>\n",
       "      <td>2024-11-28</td>\n",
       "      <td>20834.0</td>\n",
       "      <td>20760.0</td>\n",
       "      <td>20844.6</td>\n",
       "      <td>20758.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4050 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date   target     open      max      min          vol   var\n",
       "0    2010-01-04   1886.7   1882.7   1890.0   1881.6  194040000.0  1.42\n",
       "1    2010-01-05   1888.4   1887.3   1891.3   1877.5  215840000.0  0.09\n",
       "2    2010-01-06   1878.4   1887.9   1893.2   1873.9  215110000.0 -0.53\n",
       "3    2010-01-07   1876.7   1878.2   1881.3   1867.6  239020000.0 -0.09\n",
       "4    2010-01-08   1892.6   1870.9   1893.3   1868.6  231540000.0  0.85\n",
       "...         ...      ...      ...      ...      ...          ...   ...\n",
       "4045 2024-11-24  20857.4  20856.5  20875.3  20851.2          NaN  0.27\n",
       "4046 2024-11-25  20762.4  20860.9  20998.5  20706.3          NaN -0.46\n",
       "4047 2024-11-26  20909.2  20760.2  20946.8  20682.3          NaN  0.71\n",
       "4048 2024-11-27  20759.0  20911.8  20939.9  20612.2          NaN -0.72\n",
       "4049 2024-11-28  20834.0  20760.0  20844.6  20758.8          NaN  0.36\n",
       "\n",
       "[4050 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b5f849",
   "metadata": {},
   "source": [
    "## ADD INDICATORS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fec0805",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nicov\\Documents\\Github\\QuantTrader-TFT\\tft_helper.py:1059: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.ffill()\n"
     ]
    }
   ],
   "source": [
    "df = add_global_indicators(df, PIB_relevant_countries, date_start, date_end)\n",
    "df = add_indicators(df, ts_indicator_params, categorical_tendency_vars=True)\n",
    "df = df.rename(columns={\"target\": \"exog_syp500\"})\n",
    "df = df.rename(columns={\"target_smoothed_2\": \"target\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8103608c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>exog_syp500</th>\n",
       "      <th>open</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>var</th>\n",
       "      <th>exog_Nasdaq</th>\n",
       "      <th>exog_IBEX35</th>\n",
       "      <th>exog_EUStoxx50</th>\n",
       "      <th>exog_DowJones</th>\n",
       "      <th>...</th>\n",
       "      <th>bullish_rsi</th>\n",
       "      <th>bearish_rsi</th>\n",
       "      <th>bullish_bollinger</th>\n",
       "      <th>bearish_bollinger</th>\n",
       "      <th>bullish_macd</th>\n",
       "      <th>bearish_macd</th>\n",
       "      <th>bullish_atr</th>\n",
       "      <th>bearish_atr</th>\n",
       "      <th>bullish_trend</th>\n",
       "      <th>bearish_trend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>1133.00</td>\n",
       "      <td>1116.60</td>\n",
       "      <td>1133.90</td>\n",
       "      <td>1116.60</td>\n",
       "      <td>1.61</td>\n",
       "      <td>1886.70</td>\n",
       "      <td>12145.1</td>\n",
       "      <td>2324.48</td>\n",
       "      <td>10583.96</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>1136.50</td>\n",
       "      <td>1132.70</td>\n",
       "      <td>1136.60</td>\n",
       "      <td>1129.70</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1888.43</td>\n",
       "      <td>12204.4</td>\n",
       "      <td>2324.48</td>\n",
       "      <td>10572.02</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-06</td>\n",
       "      <td>1137.10</td>\n",
       "      <td>1135.70</td>\n",
       "      <td>1139.20</td>\n",
       "      <td>1134.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1878.42</td>\n",
       "      <td>12222.5</td>\n",
       "      <td>2324.48</td>\n",
       "      <td>10573.68</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-07</td>\n",
       "      <td>1141.70</td>\n",
       "      <td>1136.30</td>\n",
       "      <td>1142.50</td>\n",
       "      <td>1131.30</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1876.72</td>\n",
       "      <td>12166.3</td>\n",
       "      <td>2324.48</td>\n",
       "      <td>10606.86</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-08</td>\n",
       "      <td>1145.00</td>\n",
       "      <td>1140.50</td>\n",
       "      <td>1145.40</td>\n",
       "      <td>1136.20</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1892.59</td>\n",
       "      <td>12163.0</td>\n",
       "      <td>2324.48</td>\n",
       "      <td>10618.19</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3661</th>\n",
       "      <td>2024-07-23</td>\n",
       "      <td>5555.74</td>\n",
       "      <td>5565.30</td>\n",
       "      <td>5585.34</td>\n",
       "      <td>5550.90</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>19754.34</td>\n",
       "      <td>11212.7</td>\n",
       "      <td>4916.80</td>\n",
       "      <td>40358.09</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3662</th>\n",
       "      <td>2024-07-24</td>\n",
       "      <td>5427.13</td>\n",
       "      <td>5505.84</td>\n",
       "      <td>5508.04</td>\n",
       "      <td>5419.98</td>\n",
       "      <td>-2.31</td>\n",
       "      <td>19032.39</td>\n",
       "      <td>11210.1</td>\n",
       "      <td>4861.87</td>\n",
       "      <td>39853.87</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3663</th>\n",
       "      <td>2024-07-25</td>\n",
       "      <td>5399.22</td>\n",
       "      <td>5428.70</td>\n",
       "      <td>5491.59</td>\n",
       "      <td>5390.95</td>\n",
       "      <td>-0.51</td>\n",
       "      <td>18830.59</td>\n",
       "      <td>11145.6</td>\n",
       "      <td>4811.28</td>\n",
       "      <td>39935.07</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3664</th>\n",
       "      <td>2024-07-26</td>\n",
       "      <td>5459.10</td>\n",
       "      <td>5433.67</td>\n",
       "      <td>5488.32</td>\n",
       "      <td>5430.70</td>\n",
       "      <td>1.11</td>\n",
       "      <td>19023.66</td>\n",
       "      <td>11165.9</td>\n",
       "      <td>4862.50</td>\n",
       "      <td>40589.34</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3665</th>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>5463.54</td>\n",
       "      <td>5476.55</td>\n",
       "      <td>5487.74</td>\n",
       "      <td>5444.44</td>\n",
       "      <td>0.08</td>\n",
       "      <td>19059.49</td>\n",
       "      <td>11117.8</td>\n",
       "      <td>4815.39</td>\n",
       "      <td>40539.93</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3666 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  exog_syp500     open      max      min   var  exog_Nasdaq  \\\n",
       "0    2010-01-04      1133.00  1116.60  1133.90  1116.60  1.61      1886.70   \n",
       "1    2010-01-05      1136.50  1132.70  1136.60  1129.70  0.31      1888.43   \n",
       "2    2010-01-06      1137.10  1135.70  1139.20  1134.00  0.05      1878.42   \n",
       "3    2010-01-07      1141.70  1136.30  1142.50  1131.30  0.40      1876.72   \n",
       "4    2010-01-08      1145.00  1140.50  1145.40  1136.20  0.29      1892.59   \n",
       "...         ...          ...      ...      ...      ...   ...          ...   \n",
       "3661 2024-07-23      5555.74  5565.30  5585.34  5550.90 -0.16     19754.34   \n",
       "3662 2024-07-24      5427.13  5505.84  5508.04  5419.98 -2.31     19032.39   \n",
       "3663 2024-07-25      5399.22  5428.70  5491.59  5390.95 -0.51     18830.59   \n",
       "3664 2024-07-26      5459.10  5433.67  5488.32  5430.70  1.11     19023.66   \n",
       "3665 2024-07-29      5463.54  5476.55  5487.74  5444.44  0.08     19059.49   \n",
       "\n",
       "      exog_IBEX35  exog_EUStoxx50  exog_DowJones  ...  bullish_rsi  \\\n",
       "0         12145.1         2324.48       10583.96  ...            0   \n",
       "1         12204.4         2324.48       10572.02  ...            0   \n",
       "2         12222.5         2324.48       10573.68  ...            0   \n",
       "3         12166.3         2324.48       10606.86  ...            0   \n",
       "4         12163.0         2324.48       10618.19  ...            0   \n",
       "...           ...             ...            ...  ...          ...   \n",
       "3661      11212.7         4916.80       40358.09  ...            0   \n",
       "3662      11210.1         4861.87       39853.87  ...            0   \n",
       "3663      11145.6         4811.28       39935.07  ...            0   \n",
       "3664      11165.9         4862.50       40589.34  ...            0   \n",
       "3665      11117.8         4815.39       40539.93  ...            0   \n",
       "\n",
       "      bearish_rsi  bullish_bollinger  bearish_bollinger  bullish_macd  \\\n",
       "0               0                  0                  0             0   \n",
       "1               0                  0                  0             1   \n",
       "2               0                  0                  0             1   \n",
       "3               0                  0                  0             1   \n",
       "4               0                  0                  0             1   \n",
       "...           ...                ...                ...           ...   \n",
       "3661            0                  0                  0             0   \n",
       "3662            0                  0                  0             0   \n",
       "3663            0                  1                  0             0   \n",
       "3664            0                  0                  0             0   \n",
       "3665            0                  0                  0             0   \n",
       "\n",
       "     bearish_macd  bullish_atr  bearish_atr  bullish_trend  bearish_trend  \n",
       "0               0            0            0              0              0  \n",
       "1               0            0            0              0              0  \n",
       "2               0            0            0              0              0  \n",
       "3               0            0            0              0              0  \n",
       "4               0            0            0              0              0  \n",
       "...           ...          ...          ...            ...            ...  \n",
       "3661            1            1            0              0              0  \n",
       "3662            1            1            0              0              0  \n",
       "3663            1            1            0              1              0  \n",
       "3664            1            1            0              0              0  \n",
       "3665            1            1            0              0              0  \n",
       "\n",
       "[3666 rows x 74 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2bef641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHift indicator values\n",
    "cols_to_shift = [col for col in df.columns[3:] if not (col.startswith('AAII') or col.startswith('PIB'))]\n",
    "df[cols_to_shift] = df[cols_to_shift].shift(shift)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "179a60de",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.copy()\n",
    "data[\"group\"] = 1\n",
    "\n",
    "# Supongamos que tu DataFrame se llama 'data' y que la columna 'Date' tiene las fechas\n",
    "# Crear una lista de días festivos (ejemplo, agrega tus días festivos)\n",
    "dias_festivos = pd.to_datetime([\"2024-01-01\", \"2024-12-25\", ])  # Añade más días festivos\n",
    "\n",
    "# Meses del año (convertir a nombres de meses)\n",
    "data[\"month\"] = data[\"Date\"].dt.strftime('%B')  # Ejemplo: \"January\", \"February\", etc.\n",
    "\n",
    "# Días del año (de 1 a 365 o 366 en años bisiestos), convertir en cadena\n",
    "data[\"day_of_year\"] = data[\"Date\"].dt.dayofyear.astype(str)  # Convertir el número de día a cadena\n",
    "\n",
    "# Días de la semana (de lunes a viernes: 0 = lunes, 4 = viernes), convertir a nombre de día\n",
    "data[\"weekday\"] = data[\"Date\"].dt.strftime('%A')  # Ejemplo: \"Monday\", \"Tuesday\", etc.\n",
    "\n",
    "# Filtrar para eliminar sábados y domingos\n",
    "data = data[data[\"weekday\"].isin([\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\"])]\n",
    "\n",
    "# Identificar si el día es festivo (usar \"Yes\" o \"No\" en lugar de 1 o 0)\n",
    "data[\"is_holiday\"] = data[\"Date\"].isin(dias_festivos).map({True: \"Yes\", False: \"No\"})\n",
    "\n",
    "data[\"time_idx\"] = data.index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0651f8e",
   "metadata": {},
   "source": [
    " VARIABLES GROUPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa586286",
   "metadata": {},
   "outputs": [],
   "source": [
    "rest=['Date', 'target',\n",
    "'FEDFUNDS', 'open', 'max', 'min', 'var',\n",
    "'MACD', 'Signal_Line',\n",
    "'group', 'month', 'day_of_year', 'weekday','is_holiday', 'time_idx']\n",
    "PIB_cols = [col for col in df.columns if col.startswith('PIB')]\n",
    "AAII_cols = [col for col in df.columns if col.startswith('AAII')]\n",
    "VIX_cols = [col for col in df.columns if col.endswith('VIX')]\n",
    "SMA_cols = [col for col in df.columns if col.startswith('SMA')]\n",
    "EMA_cols = [col for col in df.columns if col.startswith('EMA')]\n",
    "lag_cols = [col for col in df.columns if col.startswith('target_lag')]\n",
    "target_smoothed_cols = [col for col in df.columns if col.startswith('target_smoothed')]\n",
    "RSI_cols = [col for col in df.columns if col.startswith('RSI')]\n",
    "Bollinger_cols = [col for col in df.columns if col.startswith('Bollinger')]\n",
    "ATR_cols = [col for col in df.columns if col.startswith('ATR')]\n",
    "CCI_cols = [col for col in df.columns if col.startswith('CCI')]\n",
    "ROC_cols = [col for col in df.columns if col.startswith('ROC')]\n",
    "Williams_cols = [col for col in df.columns if col.startswith('Williams')]\n",
    "Stochastic_cols = [col for col in df.columns if col.startswith('Stochastic')]\n",
    "bullish_cols = [col for col in df.columns if col.startswith('bullish')]\n",
    "bearish_cols = [col for col in df.columns if col.startswith('bearish')]\n",
    "exog_ts = [col for col in df.columns if col.startswith('exog')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa86e03",
   "metadata": {},
   "source": [
    "## TRAIN - TEST SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c2fd2fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "full = data.copy()\n",
    "cols_to_convert = [\"target\", \"open\", \"max\", \"min\", \"var\", \"MACD\", \"Signal_Line\"] + SMA_cols + EMA_cols + Bollinger_cols + ATR_cols + CCI_cols + ROC_cols + Williams_cols + Stochastic_cols + exog_ts + VIX_cols + lag_cols + target_smoothed_cols + RSI_cols\n",
    "full[cols_to_convert] = full[cols_to_convert].apply(pd.to_numeric, errors='coerce')\n",
    "full = full.ffill().bfill()\n",
    "\n",
    "data = full[:-test_len]\n",
    "test = full[-test_len:]\n",
    "data = data.reset_index(drop=True)\n",
    "data = data.dropna()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(data[\"Date\"][-200:], data[\"target\"][-200:], color=\"blue\", label=\"Train\")\n",
    "plt.plot(test[\"Date\"][-200:], test[\"target\"][-200:], color=\"green\", label=\"Test\")\n",
    "\n",
    "plt.xlabel(\"Fecha y Hora\")\n",
    "plt.ylabel(\"Precio Spot\")\n",
    "plt.title(\"Precio Spot en función de Fecha y Hora\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "740262e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>exog_syp500</th>\n",
       "      <th>open</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>var</th>\n",
       "      <th>exog_Nasdaq</th>\n",
       "      <th>exog_IBEX35</th>\n",
       "      <th>exog_EUStoxx50</th>\n",
       "      <th>exog_DowJones</th>\n",
       "      <th>...</th>\n",
       "      <th>bullish_atr</th>\n",
       "      <th>bearish_atr</th>\n",
       "      <th>bullish_trend</th>\n",
       "      <th>bearish_trend</th>\n",
       "      <th>group</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>weekday</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>time_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>1133.00</td>\n",
       "      <td>1116.60</td>\n",
       "      <td>1133.90</td>\n",
       "      <td>1116.60</td>\n",
       "      <td>1.61</td>\n",
       "      <td>1886.70</td>\n",
       "      <td>12145.1</td>\n",
       "      <td>2324.48</td>\n",
       "      <td>10583.96</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>January</td>\n",
       "      <td>4</td>\n",
       "      <td>Monday</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>1136.50</td>\n",
       "      <td>1132.70</td>\n",
       "      <td>1133.90</td>\n",
       "      <td>1116.60</td>\n",
       "      <td>1.61</td>\n",
       "      <td>1886.70</td>\n",
       "      <td>12145.1</td>\n",
       "      <td>2324.48</td>\n",
       "      <td>10583.96</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>January</td>\n",
       "      <td>5</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-06</td>\n",
       "      <td>1137.10</td>\n",
       "      <td>1135.70</td>\n",
       "      <td>1136.60</td>\n",
       "      <td>1129.70</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1888.43</td>\n",
       "      <td>12204.4</td>\n",
       "      <td>2324.48</td>\n",
       "      <td>10572.02</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>January</td>\n",
       "      <td>6</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-07</td>\n",
       "      <td>1141.70</td>\n",
       "      <td>1136.30</td>\n",
       "      <td>1139.20</td>\n",
       "      <td>1134.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1878.42</td>\n",
       "      <td>12222.5</td>\n",
       "      <td>2324.48</td>\n",
       "      <td>10573.68</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>January</td>\n",
       "      <td>7</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>No</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-08</td>\n",
       "      <td>1145.00</td>\n",
       "      <td>1140.50</td>\n",
       "      <td>1142.50</td>\n",
       "      <td>1131.30</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1876.72</td>\n",
       "      <td>12166.3</td>\n",
       "      <td>2324.48</td>\n",
       "      <td>10606.86</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>January</td>\n",
       "      <td>8</td>\n",
       "      <td>Friday</td>\n",
       "      <td>No</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3561</th>\n",
       "      <td>2024-02-28</td>\n",
       "      <td>5069.76</td>\n",
       "      <td>5067.20</td>\n",
       "      <td>5080.69</td>\n",
       "      <td>5057.29</td>\n",
       "      <td>0.17</td>\n",
       "      <td>17971.05</td>\n",
       "      <td>10113.8</td>\n",
       "      <td>4885.74</td>\n",
       "      <td>38972.41</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>February</td>\n",
       "      <td>59</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>No</td>\n",
       "      <td>3561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3562</th>\n",
       "      <td>2024-02-29</td>\n",
       "      <td>5096.27</td>\n",
       "      <td>5085.36</td>\n",
       "      <td>5077.37</td>\n",
       "      <td>5058.35</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>17874.50</td>\n",
       "      <td>10068.6</td>\n",
       "      <td>4883.77</td>\n",
       "      <td>38949.02</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>February</td>\n",
       "      <td>60</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>No</td>\n",
       "      <td>3562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3563</th>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>5137.08</td>\n",
       "      <td>5098.51</td>\n",
       "      <td>5104.99</td>\n",
       "      <td>5061.89</td>\n",
       "      <td>0.52</td>\n",
       "      <td>18043.85</td>\n",
       "      <td>10001.3</td>\n",
       "      <td>4877.77</td>\n",
       "      <td>38996.39</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>March</td>\n",
       "      <td>61</td>\n",
       "      <td>Friday</td>\n",
       "      <td>No</td>\n",
       "      <td>3563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3564</th>\n",
       "      <td>2024-03-04</td>\n",
       "      <td>5130.95</td>\n",
       "      <td>5130.99</td>\n",
       "      <td>5140.33</td>\n",
       "      <td>5094.16</td>\n",
       "      <td>0.80</td>\n",
       "      <td>18302.91</td>\n",
       "      <td>10064.7</td>\n",
       "      <td>4894.86</td>\n",
       "      <td>39087.38</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>March</td>\n",
       "      <td>64</td>\n",
       "      <td>Monday</td>\n",
       "      <td>No</td>\n",
       "      <td>3564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3565</th>\n",
       "      <td>2024-03-05</td>\n",
       "      <td>5078.65</td>\n",
       "      <td>5110.52</td>\n",
       "      <td>5149.67</td>\n",
       "      <td>5127.18</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>18226.48</td>\n",
       "      <td>10069.8</td>\n",
       "      <td>4912.92</td>\n",
       "      <td>38989.83</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>March</td>\n",
       "      <td>65</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>No</td>\n",
       "      <td>3565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3566 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  exog_syp500     open      max      min   var  exog_Nasdaq  \\\n",
       "0    2010-01-04      1133.00  1116.60  1133.90  1116.60  1.61      1886.70   \n",
       "1    2010-01-05      1136.50  1132.70  1133.90  1116.60  1.61      1886.70   \n",
       "2    2010-01-06      1137.10  1135.70  1136.60  1129.70  0.31      1888.43   \n",
       "3    2010-01-07      1141.70  1136.30  1139.20  1134.00  0.05      1878.42   \n",
       "4    2010-01-08      1145.00  1140.50  1142.50  1131.30  0.40      1876.72   \n",
       "...         ...          ...      ...      ...      ...   ...          ...   \n",
       "3561 2024-02-28      5069.76  5067.20  5080.69  5057.29  0.17     17971.05   \n",
       "3562 2024-02-29      5096.27  5085.36  5077.37  5058.35 -0.17     17874.50   \n",
       "3563 2024-03-01      5137.08  5098.51  5104.99  5061.89  0.52     18043.85   \n",
       "3564 2024-03-04      5130.95  5130.99  5140.33  5094.16  0.80     18302.91   \n",
       "3565 2024-03-05      5078.65  5110.52  5149.67  5127.18 -0.12     18226.48   \n",
       "\n",
       "      exog_IBEX35  exog_EUStoxx50  exog_DowJones  ...  bullish_atr  \\\n",
       "0         12145.1         2324.48       10583.96  ...            0   \n",
       "1         12145.1         2324.48       10583.96  ...            0   \n",
       "2         12204.4         2324.48       10572.02  ...            0   \n",
       "3         12222.5         2324.48       10573.68  ...            0   \n",
       "4         12166.3         2324.48       10606.86  ...            0   \n",
       "...           ...             ...            ...  ...          ...   \n",
       "3561      10113.8         4885.74       38972.41  ...            0   \n",
       "3562      10068.6         4883.77       38949.02  ...            0   \n",
       "3563      10001.3         4877.77       38996.39  ...            0   \n",
       "3564      10064.7         4894.86       39087.38  ...            0   \n",
       "3565      10069.8         4912.92       38989.83  ...            0   \n",
       "\n",
       "      bearish_atr  bullish_trend  bearish_trend  group     month  day_of_year  \\\n",
       "0               0              0              0      1   January            4   \n",
       "1               0              0              0      1   January            5   \n",
       "2               0              0              0      1   January            6   \n",
       "3               0              0              0      1   January            7   \n",
       "4               0              0              0      1   January            8   \n",
       "...           ...            ...            ...    ...       ...          ...   \n",
       "3561            1              0              0      1  February           59   \n",
       "3562            1              0              0      1  February           60   \n",
       "3563            1              0              0      1     March           61   \n",
       "3564            1              0              0      1     March           64   \n",
       "3565            1              0              0      1     March           65   \n",
       "\n",
       "        weekday  is_holiday  time_idx  \n",
       "0        Monday          No         0  \n",
       "1       Tuesday          No         1  \n",
       "2     Wednesday          No         2  \n",
       "3      Thursday          No         3  \n",
       "4        Friday          No         4  \n",
       "...         ...         ...       ...  \n",
       "3561  Wednesday          No      3561  \n",
       "3562   Thursday          No      3562  \n",
       "3563     Friday          No      3563  \n",
       "3564     Monday          No      3564  \n",
       "3565    Tuesday          No      3565  \n",
       "\n",
       "[3566 rows x 80 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a04371",
   "metadata": {},
   "source": [
    "<!-- ## DF FINL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4fc650",
   "metadata": {},
   "source": [
    "## TimeSeriesDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afdbea69",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "max_prediction_length = pred_len\n",
    "max_encoder_length = n_prev_len \n",
    "# Ajusta training_cutoff para reservar un rango más amplio para la validación\n",
    "# validation_size = 50  # ajusta según el tamaño deseado para el conjunto de validación\n",
    "training_cutoff = data[\"time_idx\"].max() - max_prediction_length #- validation_size\n",
    "\n",
    "train = TimeSeriesDataSet(\n",
    "    data[lambda x: x.time_idx <= training_cutoff],\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"target\",\n",
    "    group_ids=[group],\n",
    "    min_encoder_length=max_encoder_length,  # keep encoder length long (as it is in the validation set)\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    # min_prediction_length=24,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    static_categoricals=[],\n",
    "    static_reals=[],\n",
    "    time_varying_known_categoricals=[\"month\", \"weekday\", \"day_of_year\", \"is_holiday\"],  # group of categorical variables can be treated as one variable\n",
    "    time_varying_known_reals=[\"Date\", \"time_idx\", 'FEDFUNDS'] + AAII_cols + PIB_cols,\n",
    "                                        \n",
    "    time_varying_unknown_categoricals=  bullish_cols +  bearish_cols,\n",
    "    time_varying_unknown_reals=[\n",
    "        \"target\",\n",
    "        \"open\",\n",
    "        \"max\",\n",
    "        \"min\",\n",
    "        # \"vol\",\n",
    "        \"var\",\n",
    "        \"MACD\",\n",
    "        \"Signal_Line\",\n",
    "    ]     + \n",
    "    lag_cols + \n",
    "    SMA_cols +\n",
    "    EMA_cols +\n",
    "    RSI_cols +\n",
    "    Bollinger_cols +\n",
    "    ATR_cols +\n",
    "    CCI_cols +\n",
    "    ROC_cols +\n",
    "    Stochastic_cols +\n",
    "    Williams_cols +\n",
    "    VIX_cols +\n",
    "    exog_ts +\n",
    "    target_smoothed_cols\n",
    "    ,\n",
    "    # lags={\"target\": list(range(1, 5))},\n",
    "    # target_normalizer=GroupNormalizer(\"standard\", groups=[group], transformation=\"softplus\"),\n",
    "    # use softplus and normalize by group\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    allow_missing_timesteps=True,\n",
    "    # add_encoder_length=True,\n",
    "    categorical_encoders={\n",
    "        \"month\": pytorch_forecasting.data.encoders.NaNLabelEncoder(add_nan=True),\n",
    "        \"weekday\": pytorch_forecasting.data.encoders.NaNLabelEncoder(add_nan=True),\n",
    "        \"day_of_year\": pytorch_forecasting.data.encoders.NaNLabelEncoder(add_nan=True),\n",
    "    },\n",
    ")\n",
    "\n",
    "validation = TimeSeriesDataSet.from_dataset(train,  data, predict=True, stop_randomization=True)\n",
    "# test = TimeSeriesDataSet.from_dataset(training, test_data, predict=True, stop_randomization=True)\n",
    "\n",
    "# create dataloaders for model\n",
    "batch_size = 32  # set this between 32 to 128\n",
    "train_dataloader = train.to_dataloader(\n",
    "    train=True, batch_size=batch_size, num_workers=7, persistent_workers=True\n",
    ")\n",
    "val_dataloader = validation.to_dataloader(\n",
    "    train=False, batch_size=batch_size, num_workers=7, persistent_workers=True\n",
    ")\n",
    "# test_dataloader = test.to_dataloader(train=False, batch_size=batch_size, num_workers=11, persistent_workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b716d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "validation_data = data[lambda x: x.time_idx > training_cutoff]\n",
    "print(len(validation_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1db5ef6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeSeriesDataSet[length=1](\n",
       "\ttime_idx='time_idx',\n",
       "\ttarget='target',\n",
       "\tgroup_ids=['group'],\n",
       "\tweight=None,\n",
       "\tmax_encoder_length=50,\n",
       "\tmin_encoder_length=50,\n",
       "\tmin_prediction_idx=0,\n",
       "\tmin_prediction_length=25,\n",
       "\tmax_prediction_length=25,\n",
       "\tstatic_categoricals=[],\n",
       "\tstatic_reals=['target_center', 'target_scale'],\n",
       "\ttime_varying_known_categoricals=['month', 'weekday', 'day_of_year', 'is_holiday'],\n",
       "\ttime_varying_known_reals=['Date', 'time_idx', 'FEDFUNDS', 'AAII_Bullish', 'AAII_Neutral', 'AAII_Bearish', 'PIB_USA', 'PIB_CHN', 'PIB_DEU', 'PIB_JPN', 'PIB_IND', 'PIB_BRA', 'PIB_CAN', 'relative_time_idx'],\n",
       "\ttime_varying_unknown_categoricals=['bullish_sma_50_200', 'bullish_rsi', 'bullish_bollinger', 'bullish_macd', 'bullish_atr', 'bullish_trend', 'bearish_sma_50_200', 'bearish_rsi', 'bearish_bollinger', 'bearish_macd', 'bearish_atr', 'bearish_trend'],\n",
       "\ttime_varying_unknown_reals=['target', 'open', 'max', 'min', 'var', 'MACD', 'Signal_Line', 'target_lag1', 'target_lag2', 'target_lag3', 'target_lag4', 'target_lag5', 'target_lag6', 'target_lag7', 'target_lag8', 'target_lag9', 'target_lag10', 'SMA_5', 'SMA_10', 'SMA_20', 'SMA_50', 'SMA_100', 'SMA_200', 'EMA_5', 'EMA_10', 'EMA_20', 'EMA_50', 'EMA_100', 'EMA_200', 'RSI_14', 'Bollinger_Upper_20', 'Bollinger_Lower_20', 'ATR_14', 'CCI_10', 'CCI_20', 'ROC_10', 'ROC_14', 'ROC_20', 'Stochastic_14_K', 'Stochastic_14_D', 'Williams_%R_14', 'VIX', 'EUVIX', 'exog_syp500', 'exog_Nasdaq', 'exog_IBEX35', 'exog_EUStoxx50', 'exog_DowJones', 'exog_BTC', 'target_smoothed_1'],\n",
       "\tvariable_groups={},\n",
       "\tconstant_fill_strategy={},\n",
       "\tallow_missing_timesteps=True,\n",
       "\tlags={},\n",
       "\tadd_relative_time_idx=True,\n",
       "\tadd_target_scales=True,\n",
       "\tadd_encoder_length=False,\n",
       "\ttarget_normalizer=EncoderNormalizer(\n",
       "\tmethod='standard',\n",
       "\tcenter=True,\n",
       "\tmax_length=None,\n",
       "\ttransformation='relu',\n",
       "\tmethod_kwargs={}\n",
       "),\n",
       "\tcategorical_encoders={'month': NaNLabelEncoder(add_nan=True, warn=True), 'weekday': NaNLabelEncoder(add_nan=True, warn=True), 'day_of_year': NaNLabelEncoder(add_nan=True, warn=True), '__group_id__group': NaNLabelEncoder(add_nan=False, warn=True), 'is_holiday': NaNLabelEncoder(add_nan=False, warn=True), 'bullish_sma_50_200': NaNLabelEncoder(add_nan=False, warn=True), 'bullish_rsi': NaNLabelEncoder(add_nan=False, warn=True), 'bullish_bollinger': NaNLabelEncoder(add_nan=False, warn=True), 'bullish_macd': NaNLabelEncoder(add_nan=False, warn=True), 'bullish_atr': NaNLabelEncoder(add_nan=False, warn=True), 'bullish_trend': NaNLabelEncoder(add_nan=False, warn=True), 'bearish_sma_50_200': NaNLabelEncoder(add_nan=False, warn=True), 'bearish_rsi': NaNLabelEncoder(add_nan=False, warn=True), 'bearish_bollinger': NaNLabelEncoder(add_nan=False, warn=True), 'bearish_macd': NaNLabelEncoder(add_nan=False, warn=True), 'bearish_atr': NaNLabelEncoder(add_nan=False, warn=True), 'bearish_trend': NaNLabelEncoder(add_nan=False, warn=True)},\n",
       "\tscalers={'target_center': StandardScaler(), 'target_scale': StandardScaler(), 'Date': StandardScaler(), 'time_idx': StandardScaler(), 'FEDFUNDS': StandardScaler(), 'AAII_Bullish': StandardScaler(), 'AAII_Neutral': StandardScaler(), 'AAII_Bearish': StandardScaler(), 'PIB_USA': StandardScaler(), 'PIB_CHN': StandardScaler(), 'PIB_DEU': StandardScaler(), 'PIB_JPN': StandardScaler(), 'PIB_IND': StandardScaler(), 'PIB_BRA': StandardScaler(), 'PIB_CAN': StandardScaler(), 'relative_time_idx': StandardScaler(), 'open': StandardScaler(), 'max': StandardScaler(), 'min': StandardScaler(), 'var': StandardScaler(), 'MACD': StandardScaler(), 'Signal_Line': StandardScaler(), 'target_lag1': StandardScaler(), 'target_lag2': StandardScaler(), 'target_lag3': StandardScaler(), 'target_lag4': StandardScaler(), 'target_lag5': StandardScaler(), 'target_lag6': StandardScaler(), 'target_lag7': StandardScaler(), 'target_lag8': StandardScaler(), 'target_lag9': StandardScaler(), 'target_lag10': StandardScaler(), 'SMA_5': StandardScaler(), 'SMA_10': StandardScaler(), 'SMA_20': StandardScaler(), 'SMA_50': StandardScaler(), 'SMA_100': StandardScaler(), 'SMA_200': StandardScaler(), 'EMA_5': StandardScaler(), 'EMA_10': StandardScaler(), 'EMA_20': StandardScaler(), 'EMA_50': StandardScaler(), 'EMA_100': StandardScaler(), 'EMA_200': StandardScaler(), 'RSI_14': StandardScaler(), 'Bollinger_Upper_20': StandardScaler(), 'Bollinger_Lower_20': StandardScaler(), 'ATR_14': StandardScaler(), 'CCI_10': StandardScaler(), 'CCI_20': StandardScaler(), 'ROC_10': StandardScaler(), 'ROC_14': StandardScaler(), 'ROC_20': StandardScaler(), 'Stochastic_14_K': StandardScaler(), 'Stochastic_14_D': StandardScaler(), 'Williams_%R_14': StandardScaler(), 'VIX': StandardScaler(), 'EUVIX': StandardScaler(), 'exog_syp500': StandardScaler(), 'exog_Nasdaq': StandardScaler(), 'exog_IBEX35': StandardScaler(), 'exog_EUStoxx50': StandardScaler(), 'exog_DowJones': StandardScaler(), 'exog_BTC': StandardScaler(), 'target_smoothed_1': StandardScaler()},\n",
       "\trandomize_length=None,\n",
       "\tpredict_mode=True\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2a24e8",
   "metadata": {},
   "source": [
    "\n",
    "# LEARNIG RATE FINDER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fa807d",
   "metadata": {},
   "source": [
    "En primer lugar realizamos un estudio para hallar de forma aproximada el valor optimo de tasa de aprendizaje.  No es recomendable al 100% usar el valor sugerido directamente pues a veces no encuentra el mejor, sin embargo si que da un muy buen punto de partida por donde empezar a probar. Para ello usamos un modelo TFT cualquiera basico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54055c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if lr_finder:\n",
    "    res = get_best_lr(train, train_dataloader, val_dataloader, **tft_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008a1fdd",
   "metadata": {},
   "source": [
    "# MODELLING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927621bc",
   "metadata": {},
   "source": [
    "## TRAIN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "152ce290",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not grid_search:\n",
    "    # tft_params[\"learning_rate\"] = 0.01\n",
    "    tft, val_loss = tft_trainer(train, train_dataloader, val_dataloader, max_epochs=epochs, **tft_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0f0114",
   "metadata": {},
   "source": [
    "### EVAL MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba6ae28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not grid_search:\n",
    "    preds = tft_predict(tft, val_dataloader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f4ad1d",
   "metadata": {},
   "source": [
    "## GRID SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45763d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------------------------------------------- \n",
      " Probando combinación aleatoria 1/100: {'gradient_clip_val': 0.01, 'hidden_size': 8, 'dropout': 0.3, 'hidden_continuous_size': 64, 'attention_head_size': 8, 'learning_rate': 0.005, 'loss': QuantileLoss(quantiles=[0.02, 0.1, 0.25, 0.5, 0.75, 0.9, 0.98]), 'test_len': 100, 'pred_len': 25, 'n_prev_len': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\nicov\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:47\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m trainer_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "File \u001b[1;32mc:\\Users\\nicov\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:574\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    568\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[0;32m    570\u001b[0m     ckpt_path,\n\u001b[0;32m    571\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    572\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    573\u001b[0m )\n\u001b[1;32m--> 574\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n",
      "File \u001b[1;32mc:\\Users\\nicov\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:957\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m    956\u001b[0m \u001b[38;5;66;03m# strategy will configure model and move it to the device\u001b[39;00m\n\u001b[1;32m--> 957\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[38;5;66;03m# hook\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nicov\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightning\\pytorch\\strategies\\strategy.py:154\u001b[0m, in \u001b[0;36mStrategy.setup\u001b[1;34m(self, trainer)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin\u001b[38;5;241m.\u001b[39mconvert_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[1;32m--> 154\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setup_model(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n",
      "File \u001b[1;32mc:\\Users\\nicov\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightning\\pytorch\\strategies\\single_device.py:79\u001b[0m, in \u001b[0;36mSingleDeviceStrategy.model_to_device\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself.model must be set before self.model.to()\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 79\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot_device\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nicov\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightning\\fabric\\utilities\\device_dtype_mixin.py:55\u001b[0m, in \u001b[0;36m_DeviceDtypeModuleMixin.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     54\u001b[0m _update_properties(\u001b[38;5;28mself\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\nicov\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1340\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1338\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m-> 1340\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nicov\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n",
      "File \u001b[1;32mc:\\Users\\nicov\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:288\u001b[0m, in \u001b[0;36mRNNBase._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;66;03m# Resets _flat_weights\u001b[39;00m\n\u001b[0;32m    286\u001b[0m \u001b[38;5;66;03m# Note: be v. careful before removing this, as 3rd party device types\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# likely rely on this behavior to properly .to() modules like LSTM.\u001b[39;00m\n\u001b[1;32m--> 288\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_flat_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32mc:\\Users\\nicov\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:215\u001b[0m, in \u001b[0;36mRNNBase._init_flat_weights\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weight_refs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    213\u001b[0m     weakref\u001b[38;5;241m.\u001b[39mref(w) \u001b[38;5;28;01mif\u001b[39;00m w \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights\n\u001b[0;32m    214\u001b[0m ]\n\u001b[1;32m--> 215\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nicov\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:269\u001b[0m, in \u001b[0;36mRNNBase.flatten_parameters\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    268\u001b[0m     num_weights \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 269\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cudnn_rnn_flatten_weight\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_cudnn_mode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproj_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Llamada a la función de búsqueda aleatoria\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m best_model, best_params, best_val_loss \u001b[38;5;241m=\u001b[39m \u001b[43mrandom_hyperparameter_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./plots/gauss_multiexog_syp500_-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mn_prev_len\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43md-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdate_start\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdate_end\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m-lessFilters\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcsv_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./results/gauss_multiexog_syp500_-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mn_prev_len\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43md-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdate_start\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdate_end\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nicov\\Documents\\Github\\QuantTrader-TFT\\tft_helper.py:333\u001b[0m, in \u001b[0;36mrandom_hyperparameter_search\u001b[1;34m(data, train, train_dataloader, val_dataloader, test, param_grid, n_iterations, max_epochs, save_dir, csv_file)\u001b[0m\n\u001b[0;32m    330\u001b[0m start_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[0;32m    332\u001b[0m \u001b[38;5;66;03m# Entrenar el modelo con la combinación actual de hiperparámetros\u001b[39;00m\n\u001b[1;32m--> 333\u001b[0m tft, val_loss \u001b[38;5;241m=\u001b[39m tft_trainer(\n\u001b[0;32m    334\u001b[0m     train, train_dataloader, val_dataloader, max_epochs\u001b[38;5;241m=\u001b[39mmax_epochs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[0;32m    335\u001b[0m )\n\u001b[0;32m    337\u001b[0m \u001b[38;5;66;03m# Medir el tiempo de finalización del entrenamiento\u001b[39;00m\n\u001b[0;32m    338\u001b[0m end_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\n",
      "File \u001b[1;32mc:\\Users\\nicov\\Documents\\Github\\QuantTrader-TFT\\tft_helper.py:123\u001b[0m, in \u001b[0;36mtft_trainer\u001b[1;34m(train, train_dataloader, val_dataloader, max_epochs, model_path, **kwargs)\u001b[0m\n\u001b[0;32m     93\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(\n\u001b[0;32m     94\u001b[0m     max_epochs\u001b[38;5;241m=\u001b[39mmax_epochs,\n\u001b[0;32m     95\u001b[0m     accelerator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    107\u001b[0m     ],\n\u001b[0;32m    108\u001b[0m )\n\u001b[0;32m    110\u001b[0m tft \u001b[38;5;241m=\u001b[39m TemporalFusionTransformer\u001b[38;5;241m.\u001b[39mfrom_dataset(\n\u001b[0;32m    111\u001b[0m     train,\n\u001b[0;32m    112\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0.15\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    120\u001b[0m     reduce_on_plateau_patience\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreduce_on_plateau_patience\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m4\u001b[39m),\n\u001b[0;32m    121\u001b[0m )\n\u001b[1;32m--> 123\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;66;03m# Guardar el modelo entrenado\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_path:\n",
      "File \u001b[1;32mc:\\Users\\nicov\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:538\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 538\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    539\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[0;32m    540\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nicov\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:64\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n\u001b[0;32m     63\u001b[0m         launcher\u001b[38;5;241m.\u001b[39mkill(_get_sigkill_signal())\n\u001b[1;32m---> 64\u001b[0m     \u001b[43mexit\u001b[49m(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[0;32m     67\u001b[0m     _interrupt(trainer, exception)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "if grid_search == \"random\":\n",
    "    # Suprime todos los warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    # Llamada a la función de búsqueda aleatoria\n",
    "    best_model, best_params, best_val_loss = random_hyperparameter_search(\n",
    "        data,\n",
    "        train,\n",
    "        train_dataloader,\n",
    "        val_dataloader,\n",
    "        test,\n",
    "        param_grid,\n",
    "        n_iterations=100,\n",
    "        max_epochs=25,\n",
    "        save_dir=f'./plots/gauss_multiexog_syp500_-{n_prev_len}d-{date_start.replace(\"-\",\"\")}-{date_end.replace(\"-\",\"\")}-lessFilters',\n",
    "        csv_file=f\"./results/gauss_multiexog_syp500_-{n_prev_len}d-{date_start}-{date_end}.csv\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e9473e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if grid_search == \"exhaustive\":\n",
    "    \n",
    "    # Suprime todos los warnings \n",
    "\n",
    "    \n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "    # Llamada a la función de búsqueda de hiperparámetros\n",
    "    best_model, best_params, best_val_loss = exhaustive_hyperparameter_search(\n",
    "        data, train, train_dataloader, val_dataloader, test, param_grid, max_epochs=1\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
