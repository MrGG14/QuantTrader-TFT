{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18f03e0a",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f98c2c",
   "metadata": {},
   "source": [
    "Por incompatibilidades entre librerias nos vemos obligados a hacer este workaround para que solucionar los problemas de dependencias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e43a3d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nicov\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_forecasting\\models\\base_model.py:30: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import  scipy.signal.signaltools\n",
    "import numpy as np\n",
    "\n",
    "def _centered(arr, newsize):\n",
    "    # Return the center newsize portion of the array.\n",
    "    newsize = np.asarray(newsize)\n",
    "    currsize = np.array(arr.shape)\n",
    "    startind = (currsize - newsize) // 2\n",
    "    endind = startind + newsize\n",
    "    myslice = [slice(startind[k], endind[k]) for k in range(len(endind))]\n",
    "    return arr[tuple(myslice)]\n",
    "\n",
    "scipy.signal.signaltools._centered = _centered\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# import os\n",
    "# import pickle\n",
    "import pytorch_forecasting\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters\n",
    "from pytorch_forecasting import TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from lightning.pytorch.callbacks import EarlyStopping, LearningRateMonitor\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "import torch\n",
    "from pytorch_forecasting.metrics import MAE, SMAPE, PoissonLoss, QuantileLoss, MAPE, MASE\n",
    "from lightning.pytorch.tuner import Tuner\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from  scipy.signal.signaltools import _centered\n",
    "from tft_helper import *\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "torch.backends.cudnn.benchmark = True # Enables cuDNN auto-tuner for faster runtime when input sizes are consistent\n",
    "\n",
    "basepath = os.path.abspath(\"\")  # script directory\n",
    "\n",
    "sys.path.insert(1, os.path.join(basepath, \"..\\\\\"))\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "018de99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install optuna==3.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf5d2e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82736cf5",
   "metadata": {},
   "source": [
    "# PARAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f8001a",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "seq_len = 5 #sequence lenght: how many timesteps does a sequence have. For example a week could be considered a single sequence, therefore seq_len would be 5 as as the stock market opens 5 days a week.\n",
    "pred_len = 10 # prediction lenght: How many timesteps does a prediction sequence have. For example if each prediction is a full week pred_len should be 5 as the stock market opens 5 days a week.\n",
    "n_prev_len = 100 # Number of previous timesteps to take for inference. \n",
    "n_preds = 3 # number of predictions with test data\n",
    "test_len = pred_len * n_preds  # Number of timesteps to use for test data.\n",
    "group = \"group\" # If a same model should predict different stores, indices etc specify how to group them. If theres only one time series the set group col to one full of the same value.\n",
    "loss = QuantileLoss() # Loss function. \n",
    "epochs = 75 # Epochs to train the model.\n",
    "\n",
    "# Set ts date range\n",
    "date_start = '2010-01-04' #None #\"2023-06-01\"\n",
    "date_end = \"2024-7-29\"\n",
    "shift = 1 # How many times to shift values. Useful for using last indicator values (RSI, MACD...) for inference\n",
    "ts_indicator_params = {\n",
    "    \"moving_average_windows\": [5, 10, 20, 50, 100, 200], # Moving averages periods\n",
    "    \"sigma_gaussian_filter\": [1,2],\n",
    "    \"n_lags\": 10,\n",
    "                     \n",
    "                     }\n",
    "# cols_to_shift = [2:]\n",
    "\n",
    "# Set training config.\n",
    "lr_finder = False\n",
    "grid_search = \"random\"\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=10, verbose=False, mode=\"min\")\n",
    "lr_logger = LearningRateMonitor()  # log the learning rate\n",
    "# logger = TensorBoardLogger(\"lightning_logs\")  # logging results to a tensorboard\n",
    "\n",
    "# TFT training params.\n",
    "tft_params =  {\"gradient_clip_val\": 0.03, \"hidden_size\": 24, \"dropout\": 0.25, \"hidden_continuous_size\": 24, \"attention_head_size\": 4, \"learning_rate\": 0.01, \"loss\": loss, \"early_stop_callback\": early_stop_callback}\n",
    "\n",
    "\n",
    "PIB_relevant_countries = ['USA',\n",
    " 'CHN',\n",
    " 'EMU',\n",
    " 'DEU',\n",
    " 'FRA',\n",
    " 'GBR',\n",
    " 'JPN',\n",
    " 'IND',\n",
    " 'BRA',\n",
    " 'CAN',\n",
    " 'AUS',\n",
    " 'ITA',\n",
    " 'KOR',\n",
    " 'MEX',\n",
    " 'IDN',\n",
    " 'SAU',\n",
    " 'ZAF',\n",
    " 'TUR',\n",
    " 'ESP']\n",
    "\n",
    "# If grid search, set param grid.\n",
    "# param_grid = {\n",
    "#     \"gradient_clip_val\": [0.01, 0.03, 0.05],\n",
    "#     \"hidden_size\": [8, 16, 32],\n",
    "#     \"dropout\": [0.1, 0.25, 0.4],\n",
    "#     \"hidden_continuous_size\": [8, 16, 32],\n",
    "#     \"attention_head_size\": [2, 4, 8],\n",
    "#     \"learning_rate\": [0.005, 0.01, 0.03],\n",
    "#     \"loss\": [loss],\n",
    "#     \"test_len\": [test_len],\n",
    "#     \"pred_len\": [pred_len],\n",
    "#     \"n_prev_len\": [n_prev_len],\n",
    "# }\n",
    "\n",
    "param_grid = {\n",
    "    \"gradient_clip_val\": [0.01, 0.03, 0.05],\n",
    "    \"hidden_size\": [8, 16, 32],\n",
    "    \"dropout\": [0.1, 0.2, 0.3],\n",
    "    \"hidden_continuous_size\": [16, 64, 128],\n",
    "    \"attention_head_size\": [4,8,16],\n",
    "    \"learning_rate\": [0.005, 0.01, 0.03],\n",
    "    \"loss\": [loss],\n",
    "    \"test_len\": [test_len],\n",
    "    \"pred_len\": [pred_len],\n",
    "    \"n_prev_len\": [n_prev_len],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8032f7e1",
   "metadata": {
    "id": "8032f7e1"
   },
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbf23d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset does not contain volume data.\n"
     ]
    }
   ],
   "source": [
    "# Load time series data.\n",
    "df_nasdaq = load_file(file_name=\"Nasdaq\", path=\"./data/\", ftype=\"csv\")\n",
    "df_nasdaq = investing_preprocessing(df_nasdaq)\n",
    "df_nasdaq = df_nasdaq.rename(columns={\"target\": \"exog_nasdaq\"})\n",
    "\n",
    "df_ibex35 = load_file(file_name=\"Datos hist√≥ricos del IBEX 35\", path=\"./data/\", ftype=\"csv\")\n",
    "df_ibex35 = investing_preprocessing(df_ibex35)\n",
    "df_ibex35 = df_ibex35.rename(columns={\"target\": \"exog_ibex35\"})\n",
    "\n",
    "df_eustoxx = load_file(file_name=\"EUStoxx50\", path=\"./data/\", ftype=\"csv\")\n",
    "df_eustoxx = investing_preprocessing(df_eustoxx)\n",
    "df_eustoxx = df_eustoxx.rename(columns={\"target\": \"exog_eustoxx\"})\n",
    "\n",
    "df_syp500 = load_file(file_name=\"S&P500\", path=\"./data/\", ftype=\"csv\")\n",
    "df_syp500 = investing_preprocessing(df_syp500)\n",
    "\n",
    "\n",
    "df = add_ts_as_exog(df_syp500, [df_ibex35, df_nasdaq, df_eustoxx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5340bdf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>target</th>\n",
       "      <th>open</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>var</th>\n",
       "      <th>exog_ibex35</th>\n",
       "      <th>exog_nasdaq</th>\n",
       "      <th>exog_eustoxx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>1133.00</td>\n",
       "      <td>1116.60</td>\n",
       "      <td>1133.90</td>\n",
       "      <td>1116.60</td>\n",
       "      <td>1.61</td>\n",
       "      <td>12145.1</td>\n",
       "      <td>1886.70</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>1136.50</td>\n",
       "      <td>1132.70</td>\n",
       "      <td>1136.60</td>\n",
       "      <td>1129.70</td>\n",
       "      <td>0.31</td>\n",
       "      <td>12204.4</td>\n",
       "      <td>1888.43</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-06</td>\n",
       "      <td>1137.10</td>\n",
       "      <td>1135.70</td>\n",
       "      <td>1139.20</td>\n",
       "      <td>1134.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>12222.5</td>\n",
       "      <td>1878.42</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-07</td>\n",
       "      <td>1141.70</td>\n",
       "      <td>1136.30</td>\n",
       "      <td>1142.50</td>\n",
       "      <td>1131.30</td>\n",
       "      <td>0.40</td>\n",
       "      <td>12166.3</td>\n",
       "      <td>1876.72</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-08</td>\n",
       "      <td>1145.00</td>\n",
       "      <td>1140.50</td>\n",
       "      <td>1145.40</td>\n",
       "      <td>1136.20</td>\n",
       "      <td>0.29</td>\n",
       "      <td>12163.0</td>\n",
       "      <td>1892.59</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3724</th>\n",
       "      <td>2024-10-21</td>\n",
       "      <td>5853.98</td>\n",
       "      <td>5857.82</td>\n",
       "      <td>5866.92</td>\n",
       "      <td>5824.79</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>11841.1</td>\n",
       "      <td>20361.47</td>\n",
       "      <td>4941.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3725</th>\n",
       "      <td>2024-10-22</td>\n",
       "      <td>5851.20</td>\n",
       "      <td>5832.70</td>\n",
       "      <td>5863.04</td>\n",
       "      <td>5821.17</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>11832.7</td>\n",
       "      <td>20383.64</td>\n",
       "      <td>4939.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3726</th>\n",
       "      <td>2024-10-23</td>\n",
       "      <td>5797.42</td>\n",
       "      <td>5834.50</td>\n",
       "      <td>5834.85</td>\n",
       "      <td>5762.41</td>\n",
       "      <td>-0.92</td>\n",
       "      <td>11865.2</td>\n",
       "      <td>20066.96</td>\n",
       "      <td>4922.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3727</th>\n",
       "      <td>2024-10-24</td>\n",
       "      <td>5809.86</td>\n",
       "      <td>5817.80</td>\n",
       "      <td>5817.80</td>\n",
       "      <td>5784.92</td>\n",
       "      <td>0.21</td>\n",
       "      <td>11839.8</td>\n",
       "      <td>20232.87</td>\n",
       "      <td>4935.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3728</th>\n",
       "      <td>2024-10-25</td>\n",
       "      <td>5808.12</td>\n",
       "      <td>5826.75</td>\n",
       "      <td>5862.82</td>\n",
       "      <td>5799.98</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>11812.5</td>\n",
       "      <td>20352.02</td>\n",
       "      <td>4943.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3729 rows √ó 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date   target     open      max      min   var  exog_ibex35  \\\n",
       "0    2010-01-04  1133.00  1116.60  1133.90  1116.60  1.61      12145.1   \n",
       "1    2010-01-05  1136.50  1132.70  1136.60  1129.70  0.31      12204.4   \n",
       "2    2010-01-06  1137.10  1135.70  1139.20  1134.00  0.05      12222.5   \n",
       "3    2010-01-07  1141.70  1136.30  1142.50  1131.30  0.40      12166.3   \n",
       "4    2010-01-08  1145.00  1140.50  1145.40  1136.20  0.29      12163.0   \n",
       "...         ...      ...      ...      ...      ...   ...          ...   \n",
       "3724 2024-10-21  5853.98  5857.82  5866.92  5824.79 -0.18      11841.1   \n",
       "3725 2024-10-22  5851.20  5832.70  5863.04  5821.17 -0.05      11832.7   \n",
       "3726 2024-10-23  5797.42  5834.50  5834.85  5762.41 -0.92      11865.2   \n",
       "3727 2024-10-24  5809.86  5817.80  5817.80  5784.92  0.21      11839.8   \n",
       "3728 2024-10-25  5808.12  5826.75  5862.82  5799.98 -0.03      11812.5   \n",
       "\n",
       "      exog_nasdaq  exog_eustoxx  \n",
       "0         1886.70           NaN  \n",
       "1         1888.43           NaN  \n",
       "2         1878.42           NaN  \n",
       "3         1876.72           NaN  \n",
       "4         1892.59           NaN  \n",
       "...           ...           ...  \n",
       "3724     20361.47       4941.22  \n",
       "3725     20383.64       4939.31  \n",
       "3726     20066.96       4922.55  \n",
       "3727     20232.87       4935.45  \n",
       "3728     20352.02       4943.09  \n",
       "\n",
       "[3729 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b5f849",
   "metadata": {},
   "source": [
    "## ADD INDICATORS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9b757f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fec0805",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nicov\\Documents\\Github\\QuantTrader-TFT\\tft_helper.py:1059: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.ffill()\n"
     ]
    }
   ],
   "source": [
    "df = add_global_indicators(df, PIB_relevant_countries, date_start, date_end)\n",
    "df = add_indicators(df, ts_indicator_params, categorical_tendency_vars=True)\n",
    "df = df.rename(columns={\"target\": \"exog_syp500\"})\n",
    "df = df.rename(columns={\"target_smoothed_2\": \"target\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8103608c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>exog_syp500</th>\n",
       "      <th>open</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>var</th>\n",
       "      <th>exog_ibex35</th>\n",
       "      <th>exog_nasdaq</th>\n",
       "      <th>exog_eustoxx</th>\n",
       "      <th>AAII_Bullish</th>\n",
       "      <th>...</th>\n",
       "      <th>bullish_rsi</th>\n",
       "      <th>bearish_rsi</th>\n",
       "      <th>bullish_bollinger</th>\n",
       "      <th>bearish_bollinger</th>\n",
       "      <th>bullish_macd</th>\n",
       "      <th>bearish_macd</th>\n",
       "      <th>bullish_atr</th>\n",
       "      <th>bearish_atr</th>\n",
       "      <th>bullish_trend</th>\n",
       "      <th>bearish_trend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>1133.00</td>\n",
       "      <td>1116.60</td>\n",
       "      <td>1133.90</td>\n",
       "      <td>1116.60</td>\n",
       "      <td>1.61</td>\n",
       "      <td>12145.1</td>\n",
       "      <td>1886.70</td>\n",
       "      <td>2324.48</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>1136.50</td>\n",
       "      <td>1132.70</td>\n",
       "      <td>1136.60</td>\n",
       "      <td>1129.70</td>\n",
       "      <td>0.31</td>\n",
       "      <td>12204.4</td>\n",
       "      <td>1888.43</td>\n",
       "      <td>2324.48</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-06</td>\n",
       "      <td>1137.10</td>\n",
       "      <td>1135.70</td>\n",
       "      <td>1139.20</td>\n",
       "      <td>1134.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>12222.5</td>\n",
       "      <td>1878.42</td>\n",
       "      <td>2324.48</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-07</td>\n",
       "      <td>1141.70</td>\n",
       "      <td>1136.30</td>\n",
       "      <td>1142.50</td>\n",
       "      <td>1131.30</td>\n",
       "      <td>0.40</td>\n",
       "      <td>12166.3</td>\n",
       "      <td>1876.72</td>\n",
       "      <td>2324.48</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-08</td>\n",
       "      <td>1145.00</td>\n",
       "      <td>1140.50</td>\n",
       "      <td>1145.40</td>\n",
       "      <td>1136.20</td>\n",
       "      <td>0.29</td>\n",
       "      <td>12163.0</td>\n",
       "      <td>1892.59</td>\n",
       "      <td>2324.48</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3661</th>\n",
       "      <td>2024-07-23</td>\n",
       "      <td>5555.74</td>\n",
       "      <td>5565.30</td>\n",
       "      <td>5585.34</td>\n",
       "      <td>5550.90</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>11212.7</td>\n",
       "      <td>19754.34</td>\n",
       "      <td>4916.80</td>\n",
       "      <td>0.527473</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3662</th>\n",
       "      <td>2024-07-24</td>\n",
       "      <td>5427.13</td>\n",
       "      <td>5505.84</td>\n",
       "      <td>5508.04</td>\n",
       "      <td>5419.98</td>\n",
       "      <td>-2.31</td>\n",
       "      <td>11210.1</td>\n",
       "      <td>19032.39</td>\n",
       "      <td>4861.87</td>\n",
       "      <td>0.527473</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3663</th>\n",
       "      <td>2024-07-25</td>\n",
       "      <td>5399.22</td>\n",
       "      <td>5428.70</td>\n",
       "      <td>5491.59</td>\n",
       "      <td>5390.95</td>\n",
       "      <td>-0.51</td>\n",
       "      <td>11145.6</td>\n",
       "      <td>18830.59</td>\n",
       "      <td>4811.28</td>\n",
       "      <td>0.431734</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3664</th>\n",
       "      <td>2024-07-26</td>\n",
       "      <td>5459.10</td>\n",
       "      <td>5433.67</td>\n",
       "      <td>5488.32</td>\n",
       "      <td>5430.70</td>\n",
       "      <td>1.11</td>\n",
       "      <td>11165.9</td>\n",
       "      <td>19023.66</td>\n",
       "      <td>4862.50</td>\n",
       "      <td>0.431734</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3665</th>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>5463.54</td>\n",
       "      <td>5476.55</td>\n",
       "      <td>5487.74</td>\n",
       "      <td>5444.44</td>\n",
       "      <td>0.08</td>\n",
       "      <td>11117.8</td>\n",
       "      <td>19059.49</td>\n",
       "      <td>4815.39</td>\n",
       "      <td>0.431734</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3666 rows √ó 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  exog_syp500     open      max      min   var  exog_ibex35  \\\n",
       "0    2010-01-04      1133.00  1116.60  1133.90  1116.60  1.61      12145.1   \n",
       "1    2010-01-05      1136.50  1132.70  1136.60  1129.70  0.31      12204.4   \n",
       "2    2010-01-06      1137.10  1135.70  1139.20  1134.00  0.05      12222.5   \n",
       "3    2010-01-07      1141.70  1136.30  1142.50  1131.30  0.40      12166.3   \n",
       "4    2010-01-08      1145.00  1140.50  1145.40  1136.20  0.29      12163.0   \n",
       "...         ...          ...      ...      ...      ...   ...          ...   \n",
       "3661 2024-07-23      5555.74  5565.30  5585.34  5550.90 -0.16      11212.7   \n",
       "3662 2024-07-24      5427.13  5505.84  5508.04  5419.98 -2.31      11210.1   \n",
       "3663 2024-07-25      5399.22  5428.70  5491.59  5390.95 -0.51      11145.6   \n",
       "3664 2024-07-26      5459.10  5433.67  5488.32  5430.70  1.11      11165.9   \n",
       "3665 2024-07-29      5463.54  5476.55  5487.74  5444.44  0.08      11117.8   \n",
       "\n",
       "      exog_nasdaq  exog_eustoxx  AAII_Bullish  ...  bullish_rsi  bearish_rsi  \\\n",
       "0         1886.70       2324.48      0.410000  ...            0            0   \n",
       "1         1888.43       2324.48      0.410000  ...            0            0   \n",
       "2         1878.42       2324.48      0.410000  ...            0            0   \n",
       "3         1876.72       2324.48      0.410000  ...            0            0   \n",
       "4         1892.59       2324.48      0.410000  ...            0            0   \n",
       "...           ...           ...           ...  ...          ...          ...   \n",
       "3661     19754.34       4916.80      0.527473  ...            0            0   \n",
       "3662     19032.39       4861.87      0.527473  ...            0            0   \n",
       "3663     18830.59       4811.28      0.431734  ...            0            0   \n",
       "3664     19023.66       4862.50      0.431734  ...            0            0   \n",
       "3665     19059.49       4815.39      0.431734  ...            0            0   \n",
       "\n",
       "      bullish_bollinger bearish_bollinger  bullish_macd  bearish_macd  \\\n",
       "0                     0                 0             0             0   \n",
       "1                     0                 0             1             0   \n",
       "2                     0                 0             1             0   \n",
       "3                     0                 0             1             0   \n",
       "4                     0                 0             1             0   \n",
       "...                 ...               ...           ...           ...   \n",
       "3661                  0                 0             0             1   \n",
       "3662                  0                 0             0             1   \n",
       "3663                  1                 0             0             1   \n",
       "3664                  0                 0             0             1   \n",
       "3665                  0                 0             0             1   \n",
       "\n",
       "      bullish_atr  bearish_atr  bullish_trend  bearish_trend  \n",
       "0               0            0              0              0  \n",
       "1               0            0              0              0  \n",
       "2               0            0              0              0  \n",
       "3               0            0              0              0  \n",
       "4               0            0              0              0  \n",
       "...           ...          ...            ...            ...  \n",
       "3661            1            0              0              0  \n",
       "3662            1            0              0              0  \n",
       "3663            1            0              1              0  \n",
       "3664            1            0              0              0  \n",
       "3665            1            0              0              0  \n",
       "\n",
       "[3666 rows x 84 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2bef641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHift indicator values\n",
    "cols_to_shift = [col for col in df.columns[3:] if not (col.startswith('AAII') or col.startswith('PIB'))]\n",
    "df[cols_to_shift] = df[cols_to_shift].shift(shift)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "179a60de",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.copy()\n",
    "data[\"group\"] = 1\n",
    "\n",
    "# Supongamos que tu DataFrame se llama 'data' y que la columna 'Date' tiene las fechas\n",
    "# Crear una lista de d√≠as festivos (ejemplo, agrega tus d√≠as festivos)\n",
    "dias_festivos = pd.to_datetime([\"2024-01-01\", \"2024-12-25\", ])  # A√±ade m√°s d√≠as festivos\n",
    "\n",
    "# Meses del a√±o (convertir a nombres de meses)\n",
    "data[\"month\"] = data[\"Date\"].dt.strftime('%B')  # Ejemplo: \"January\", \"February\", etc.\n",
    "\n",
    "# D√≠as del a√±o (de 1 a 365 o 366 en a√±os bisiestos), convertir en cadena\n",
    "data[\"day_of_year\"] = data[\"Date\"].dt.dayofyear.astype(str)  # Convertir el n√∫mero de d√≠a a cadena\n",
    "\n",
    "# D√≠as de la semana (de lunes a viernes: 0 = lunes, 4 = viernes), convertir a nombre de d√≠a\n",
    "data[\"weekday\"] = data[\"Date\"].dt.strftime('%A')  # Ejemplo: \"Monday\", \"Tuesday\", etc.\n",
    "\n",
    "# Filtrar para eliminar s√°bados y domingos\n",
    "data = data[data[\"weekday\"].isin([\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\"])]\n",
    "\n",
    "# Identificar si el d√≠a es festivo (usar \"Yes\" o \"No\" en lugar de 1 o 0)\n",
    "data[\"is_holiday\"] = data[\"Date\"].isin(dias_festivos).map({True: \"Yes\", False: \"No\"})\n",
    "\n",
    "data[\"time_idx\"] = data.index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0651f8e",
   "metadata": {},
   "source": [
    " VARIABLES GROUPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa586286",
   "metadata": {},
   "outputs": [],
   "source": [
    "rest=['Date', 'target',\n",
    "'FEDFUNDS', 'open', 'max', 'min', 'var',\n",
    "'MACD', 'Signal_Line',\n",
    "'group', 'month', 'day_of_year', 'weekday','is_holiday', 'time_idx']\n",
    "PIB_cols = [col for col in df.columns if col.startswith('PIB')]\n",
    "AAII_cols = [col for col in df.columns if col.startswith('AAII')]\n",
    "VIX_cols = [col for col in df.columns if col.endswith('VIX')]\n",
    "SMA_cols = [col for col in df.columns if col.startswith('SMA')]\n",
    "EMA_cols = [col for col in df.columns if col.startswith('EMA')]\n",
    "lag_cols = [col for col in df.columns if col.startswith('target_lag')]\n",
    "target_smoothed_cols = [col for col in df.columns if col.startswith('target_smoothed')]\n",
    "RSI_cols = [col for col in df.columns if col.startswith('RSI')]\n",
    "Bollinger_cols = [col for col in df.columns if col.startswith('Bollinger')]\n",
    "ATR_cols = [col for col in df.columns if col.startswith('ATR')]\n",
    "CCI_cols = [col for col in df.columns if col.startswith('CCI')]\n",
    "ROC_cols = [col for col in df.columns if col.startswith('ROC')]\n",
    "Williams_cols = [col for col in df.columns if col.startswith('Williams')]\n",
    "Stochastic_cols = [col for col in df.columns if col.startswith('Stochastic')]\n",
    "bullish_cols = [col for col in df.columns if col.startswith('bullish')]\n",
    "bearish_cols = [col for col in df.columns if col.startswith('bearish')]\n",
    "exog_ts = [col for col in df.columns if col.startswith('exog')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa86e03",
   "metadata": {},
   "source": [
    "## TRAIN - TEST SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c2fd2fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "full = data.copy()\n",
    "cols_to_convert = [\"target\", \"open\", \"max\", \"min\", \"var\", \"MACD\", \"Signal_Line\"] + SMA_cols + EMA_cols + Bollinger_cols + ATR_cols + CCI_cols + ROC_cols + Williams_cols + Stochastic_cols + exog_ts + VIX_cols + lag_cols + target_smoothed_cols + RSI_cols\n",
    "full[cols_to_convert] = full[cols_to_convert].apply(pd.to_numeric, errors='coerce')\n",
    "full = full.ffill().bfill()\n",
    "\n",
    "data = full[:-test_len]\n",
    "test = full[-test_len:]\n",
    "data = data.reset_index(drop=True)\n",
    "data = data.dropna()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(data[\"Date\"][-200:], data[\"target\"][-200:], color=\"blue\", label=\"Train\")\n",
    "plt.plot(test[\"Date\"][-200:], test[\"target\"][-200:], color=\"green\", label=\"Test\")\n",
    "\n",
    "plt.xlabel(\"Fecha y Hora\")\n",
    "plt.ylabel(\"Precio Spot\")\n",
    "plt.title(\"Precio Spot en funci√≥n de Fecha y Hora\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "740262e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>exog_syp500</th>\n",
       "      <th>open</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>var</th>\n",
       "      <th>exog_ibex35</th>\n",
       "      <th>exog_nasdaq</th>\n",
       "      <th>exog_eustoxx</th>\n",
       "      <th>AAII_Bullish</th>\n",
       "      <th>...</th>\n",
       "      <th>bullish_atr</th>\n",
       "      <th>bearish_atr</th>\n",
       "      <th>bullish_trend</th>\n",
       "      <th>bearish_trend</th>\n",
       "      <th>group</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>weekday</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>time_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>1133.00</td>\n",
       "      <td>1116.60</td>\n",
       "      <td>1133.90</td>\n",
       "      <td>1116.60</td>\n",
       "      <td>1.61</td>\n",
       "      <td>12145.1</td>\n",
       "      <td>1886.70</td>\n",
       "      <td>2324.48</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>January</td>\n",
       "      <td>4</td>\n",
       "      <td>Monday</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>1136.50</td>\n",
       "      <td>1132.70</td>\n",
       "      <td>1133.90</td>\n",
       "      <td>1116.60</td>\n",
       "      <td>1.61</td>\n",
       "      <td>12145.1</td>\n",
       "      <td>1886.70</td>\n",
       "      <td>2324.48</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>January</td>\n",
       "      <td>5</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-06</td>\n",
       "      <td>1137.10</td>\n",
       "      <td>1135.70</td>\n",
       "      <td>1136.60</td>\n",
       "      <td>1129.70</td>\n",
       "      <td>0.31</td>\n",
       "      <td>12204.4</td>\n",
       "      <td>1888.43</td>\n",
       "      <td>2324.48</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>January</td>\n",
       "      <td>6</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-07</td>\n",
       "      <td>1141.70</td>\n",
       "      <td>1136.30</td>\n",
       "      <td>1139.20</td>\n",
       "      <td>1134.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>12222.5</td>\n",
       "      <td>1878.42</td>\n",
       "      <td>2324.48</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>January</td>\n",
       "      <td>7</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>No</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-08</td>\n",
       "      <td>1145.00</td>\n",
       "      <td>1140.50</td>\n",
       "      <td>1142.50</td>\n",
       "      <td>1131.30</td>\n",
       "      <td>0.40</td>\n",
       "      <td>12166.3</td>\n",
       "      <td>1876.72</td>\n",
       "      <td>2324.48</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>January</td>\n",
       "      <td>8</td>\n",
       "      <td>Friday</td>\n",
       "      <td>No</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3536</th>\n",
       "      <td>2024-01-23</td>\n",
       "      <td>4864.60</td>\n",
       "      <td>4856.80</td>\n",
       "      <td>4868.41</td>\n",
       "      <td>4844.05</td>\n",
       "      <td>0.22</td>\n",
       "      <td>9968.1</td>\n",
       "      <td>17330.38</td>\n",
       "      <td>4480.32</td>\n",
       "      <td>0.403756</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>January</td>\n",
       "      <td>23</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>No</td>\n",
       "      <td>3536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3537</th>\n",
       "      <td>2024-01-24</td>\n",
       "      <td>4868.55</td>\n",
       "      <td>4888.56</td>\n",
       "      <td>4866.48</td>\n",
       "      <td>4844.37</td>\n",
       "      <td>0.29</td>\n",
       "      <td>9859.2</td>\n",
       "      <td>17404.21</td>\n",
       "      <td>4465.91</td>\n",
       "      <td>0.403756</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>January</td>\n",
       "      <td>24</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>No</td>\n",
       "      <td>3537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3538</th>\n",
       "      <td>2024-01-25</td>\n",
       "      <td>4894.16</td>\n",
       "      <td>4886.66</td>\n",
       "      <td>4903.68</td>\n",
       "      <td>4865.94</td>\n",
       "      <td>0.08</td>\n",
       "      <td>9974.0</td>\n",
       "      <td>17499.30</td>\n",
       "      <td>4564.11</td>\n",
       "      <td>0.392683</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>January</td>\n",
       "      <td>25</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>No</td>\n",
       "      <td>3538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3539</th>\n",
       "      <td>2024-01-26</td>\n",
       "      <td>4890.97</td>\n",
       "      <td>4888.91</td>\n",
       "      <td>4898.15</td>\n",
       "      <td>4869.34</td>\n",
       "      <td>0.53</td>\n",
       "      <td>9916.6</td>\n",
       "      <td>17516.99</td>\n",
       "      <td>4582.26</td>\n",
       "      <td>0.392683</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>January</td>\n",
       "      <td>26</td>\n",
       "      <td>Friday</td>\n",
       "      <td>No</td>\n",
       "      <td>3539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3540</th>\n",
       "      <td>2024-01-29</td>\n",
       "      <td>4927.93</td>\n",
       "      <td>4892.95</td>\n",
       "      <td>4906.69</td>\n",
       "      <td>4881.47</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>9936.6</td>\n",
       "      <td>17421.01</td>\n",
       "      <td>4635.47</td>\n",
       "      <td>0.392683</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>January</td>\n",
       "      <td>29</td>\n",
       "      <td>Monday</td>\n",
       "      <td>No</td>\n",
       "      <td>3540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3541 rows √ó 90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  exog_syp500     open      max      min   var  exog_ibex35  \\\n",
       "0    2010-01-04      1133.00  1116.60  1133.90  1116.60  1.61      12145.1   \n",
       "1    2010-01-05      1136.50  1132.70  1133.90  1116.60  1.61      12145.1   \n",
       "2    2010-01-06      1137.10  1135.70  1136.60  1129.70  0.31      12204.4   \n",
       "3    2010-01-07      1141.70  1136.30  1139.20  1134.00  0.05      12222.5   \n",
       "4    2010-01-08      1145.00  1140.50  1142.50  1131.30  0.40      12166.3   \n",
       "...         ...          ...      ...      ...      ...   ...          ...   \n",
       "3536 2024-01-23      4864.60  4856.80  4868.41  4844.05  0.22       9968.1   \n",
       "3537 2024-01-24      4868.55  4888.56  4866.48  4844.37  0.29       9859.2   \n",
       "3538 2024-01-25      4894.16  4886.66  4903.68  4865.94  0.08       9974.0   \n",
       "3539 2024-01-26      4890.97  4888.91  4898.15  4869.34  0.53       9916.6   \n",
       "3540 2024-01-29      4927.93  4892.95  4906.69  4881.47 -0.07       9936.6   \n",
       "\n",
       "      exog_nasdaq  exog_eustoxx  AAII_Bullish  ...  bullish_atr  bearish_atr  \\\n",
       "0         1886.70       2324.48      0.410000  ...            0            0   \n",
       "1         1886.70       2324.48      0.410000  ...            0            0   \n",
       "2         1888.43       2324.48      0.410000  ...            0            0   \n",
       "3         1878.42       2324.48      0.410000  ...            0            0   \n",
       "4         1876.72       2324.48      0.410000  ...            0            0   \n",
       "...           ...           ...           ...  ...          ...          ...   \n",
       "3536     17330.38       4480.32      0.403756  ...            1            0   \n",
       "3537     17404.21       4465.91      0.403756  ...            1            0   \n",
       "3538     17499.30       4564.11      0.392683  ...            0            1   \n",
       "3539     17516.99       4582.26      0.392683  ...            0            1   \n",
       "3540     17421.01       4635.47      0.392683  ...            0            1   \n",
       "\n",
       "      bullish_trend  bearish_trend  group    month  day_of_year    weekday  \\\n",
       "0                 0              0      1  January            4     Monday   \n",
       "1                 0              0      1  January            5    Tuesday   \n",
       "2                 0              0      1  January            6  Wednesday   \n",
       "3                 0              0      1  January            7   Thursday   \n",
       "4                 0              0      1  January            8     Friday   \n",
       "...             ...            ...    ...      ...          ...        ...   \n",
       "3536              1              0      1  January           23    Tuesday   \n",
       "3537              1              0      1  January           24  Wednesday   \n",
       "3538              0              0      1  January           25   Thursday   \n",
       "3539              0              0      1  January           26     Friday   \n",
       "3540              0              0      1  January           29     Monday   \n",
       "\n",
       "      is_holiday  time_idx  \n",
       "0             No         0  \n",
       "1             No         1  \n",
       "2             No         2  \n",
       "3             No         3  \n",
       "4             No         4  \n",
       "...          ...       ...  \n",
       "3536          No      3536  \n",
       "3537          No      3537  \n",
       "3538          No      3538  \n",
       "3539          No      3539  \n",
       "3540          No      3540  \n",
       "\n",
       "[3541 rows x 90 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a04371",
   "metadata": {},
   "source": [
    "<!-- ## DF FINL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4fc650",
   "metadata": {},
   "source": [
    "## TimeSeriesDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afdbea69",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "max_prediction_length = pred_len\n",
    "max_encoder_length = n_prev_len \n",
    "# Ajusta training_cutoff para reservar un rango m√°s amplio para la validaci√≥n\n",
    "# validation_size = 50  # ajusta seg√∫n el tama√±o deseado para el conjunto de validaci√≥n\n",
    "training_cutoff = data[\"time_idx\"].max() - max_prediction_length #- validation_size\n",
    "\n",
    "train = TimeSeriesDataSet(\n",
    "    data[lambda x: x.time_idx <= training_cutoff],\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"target\",\n",
    "    group_ids=[group],\n",
    "    min_encoder_length=max_encoder_length,  # keep encoder length long (as it is in the validation set)\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    # min_prediction_length=24,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    static_categoricals=[],\n",
    "    static_reals=[],\n",
    "    time_varying_known_categoricals=[\"month\", \"weekday\", \"day_of_year\", \"is_holiday\"],  # group of categorical variables can be treated as one variable\n",
    "    time_varying_known_reals=[\"Date\", \"time_idx\", 'FEDFUNDS'] + AAII_cols + PIB_cols,\n",
    "                                        \n",
    "    time_varying_unknown_categoricals=  bullish_cols +  bearish_cols,\n",
    "    time_varying_unknown_reals=[\n",
    "        \"target\",\n",
    "        \"open\",\n",
    "        \"max\",\n",
    "        \"min\",\n",
    "        # \"vol\",\n",
    "        \"var\",\n",
    "        \"MACD\",\n",
    "        \"Signal_Line\",\n",
    "    ]     + \n",
    "    lag_cols + \n",
    "    SMA_cols +\n",
    "    EMA_cols +\n",
    "    RSI_cols +\n",
    "    Bollinger_cols +\n",
    "    ATR_cols +\n",
    "    CCI_cols +\n",
    "    ROC_cols +\n",
    "    Stochastic_cols +\n",
    "    Williams_cols +\n",
    "    VIX_cols +\n",
    "    exog_ts +\n",
    "    target_smoothed_cols\n",
    "    ,\n",
    "    # lags={\"target\": list(range(1, 5))},\n",
    "    # target_normalizer=GroupNormalizer(\"standard\", groups=[group], transformation=\"softplus\"),\n",
    "    # use softplus and normalize by group\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    allow_missing_timesteps=True,\n",
    "    # add_encoder_length=True,\n",
    "    categorical_encoders={\n",
    "        \"month\": pytorch_forecasting.data.encoders.NaNLabelEncoder(add_nan=True),\n",
    "        \"weekday\": pytorch_forecasting.data.encoders.NaNLabelEncoder(add_nan=True),\n",
    "        \"day_of_year\": pytorch_forecasting.data.encoders.NaNLabelEncoder(add_nan=True),\n",
    "    },\n",
    ")\n",
    "\n",
    "validation = TimeSeriesDataSet.from_dataset(train,  data, predict=True, stop_randomization=True)\n",
    "# test = TimeSeriesDataSet.from_dataset(training, test_data, predict=True, stop_randomization=True)\n",
    "\n",
    "# create dataloaders for model\n",
    "batch_size = 32  # set this between 32 to 128\n",
    "train_dataloader = train.to_dataloader(\n",
    "    train=True, batch_size=batch_size, num_workers=7, persistent_workers=True\n",
    ")\n",
    "val_dataloader = validation.to_dataloader(\n",
    "    train=False, batch_size=batch_size, num_workers=7, persistent_workers=True\n",
    ")\n",
    "# test_dataloader = test.to_dataloader(train=False, batch_size=batch_size, num_workers=11, persistent_workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b716d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "validation_data = data[lambda x: x.time_idx > training_cutoff]\n",
    "print(len(validation_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1db5ef6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeSeriesDataSet[length=1](\n",
       "\ttime_idx='time_idx',\n",
       "\ttarget='target',\n",
       "\tgroup_ids=['group'],\n",
       "\tweight=None,\n",
       "\tmax_encoder_length=100,\n",
       "\tmin_encoder_length=100,\n",
       "\tmin_prediction_idx=0,\n",
       "\tmin_prediction_length=25,\n",
       "\tmax_prediction_length=25,\n",
       "\tstatic_categoricals=[],\n",
       "\tstatic_reals=['target_center', 'target_scale'],\n",
       "\ttime_varying_known_categoricals=['month', 'weekday', 'day_of_year', 'is_holiday'],\n",
       "\ttime_varying_known_reals=['Date', 'time_idx', 'FEDFUNDS', 'AAII_Bullish', 'AAII_Neutral', 'AAII_Bearish', 'PIB_USA', 'PIB_CHN', 'PIB_EMU', 'PIB_DEU', 'PIB_FRA', 'PIB_GBR', 'PIB_JPN', 'PIB_IND', 'PIB_BRA', 'PIB_CAN', 'PIB_AUS', 'PIB_ITA', 'PIB_KOR', 'PIB_MEX', 'PIB_IDN', 'PIB_SAU', 'PIB_ZAF', 'PIB_TUR', 'PIB_ESP', 'relative_time_idx'],\n",
       "\ttime_varying_unknown_categoricals=['bullish_sma_50_200', 'bullish_rsi', 'bullish_bollinger', 'bullish_macd', 'bullish_atr', 'bullish_trend', 'bearish_sma_50_200', 'bearish_rsi', 'bearish_bollinger', 'bearish_macd', 'bearish_atr', 'bearish_trend'],\n",
       "\ttime_varying_unknown_reals=['target', 'open', 'max', 'min', 'var', 'MACD', 'Signal_Line', 'target_lag1', 'target_lag2', 'target_lag3', 'target_lag4', 'target_lag5', 'target_lag6', 'target_lag7', 'target_lag8', 'target_lag9', 'target_lag10', 'SMA_5', 'SMA_10', 'SMA_20', 'SMA_50', 'SMA_100', 'SMA_200', 'EMA_5', 'EMA_10', 'EMA_20', 'EMA_50', 'EMA_100', 'EMA_200', 'RSI_14', 'Bollinger_Upper_20', 'Bollinger_Lower_20', 'ATR_14', 'CCI_10', 'CCI_20', 'ROC_10', 'ROC_14', 'ROC_20', 'Stochastic_14_K', 'Stochastic_14_D', 'Williams_%R_14', 'VIX', 'EUVIX', 'exog_syp500', 'exog_ibex35', 'exog_nasdaq', 'exog_eustoxx', 'target_smoothed_1'],\n",
       "\tvariable_groups={},\n",
       "\tconstant_fill_strategy={},\n",
       "\tallow_missing_timesteps=True,\n",
       "\tlags={},\n",
       "\tadd_relative_time_idx=True,\n",
       "\tadd_target_scales=True,\n",
       "\tadd_encoder_length=False,\n",
       "\ttarget_normalizer=EncoderNormalizer(\n",
       "\tmethod='standard',\n",
       "\tcenter=True,\n",
       "\tmax_length=None,\n",
       "\ttransformation='relu',\n",
       "\tmethod_kwargs={}\n",
       "),\n",
       "\tcategorical_encoders={'month': NaNLabelEncoder(add_nan=True, warn=True), 'weekday': NaNLabelEncoder(add_nan=True, warn=True), 'day_of_year': NaNLabelEncoder(add_nan=True, warn=True), '__group_id__group': NaNLabelEncoder(add_nan=False, warn=True), 'is_holiday': NaNLabelEncoder(add_nan=False, warn=True), 'bullish_sma_50_200': NaNLabelEncoder(add_nan=False, warn=True), 'bullish_rsi': NaNLabelEncoder(add_nan=False, warn=True), 'bullish_bollinger': NaNLabelEncoder(add_nan=False, warn=True), 'bullish_macd': NaNLabelEncoder(add_nan=False, warn=True), 'bullish_atr': NaNLabelEncoder(add_nan=False, warn=True), 'bullish_trend': NaNLabelEncoder(add_nan=False, warn=True), 'bearish_sma_50_200': NaNLabelEncoder(add_nan=False, warn=True), 'bearish_rsi': NaNLabelEncoder(add_nan=False, warn=True), 'bearish_bollinger': NaNLabelEncoder(add_nan=False, warn=True), 'bearish_macd': NaNLabelEncoder(add_nan=False, warn=True), 'bearish_atr': NaNLabelEncoder(add_nan=False, warn=True), 'bearish_trend': NaNLabelEncoder(add_nan=False, warn=True)},\n",
       "\tscalers={'target_center': StandardScaler(), 'target_scale': StandardScaler(), 'Date': StandardScaler(), 'time_idx': StandardScaler(), 'FEDFUNDS': StandardScaler(), 'AAII_Bullish': StandardScaler(), 'AAII_Neutral': StandardScaler(), 'AAII_Bearish': StandardScaler(), 'PIB_USA': StandardScaler(), 'PIB_CHN': StandardScaler(), 'PIB_EMU': StandardScaler(), 'PIB_DEU': StandardScaler(), 'PIB_FRA': StandardScaler(), 'PIB_GBR': StandardScaler(), 'PIB_JPN': StandardScaler(), 'PIB_IND': StandardScaler(), 'PIB_BRA': StandardScaler(), 'PIB_CAN': StandardScaler(), 'PIB_AUS': StandardScaler(), 'PIB_ITA': StandardScaler(), 'PIB_KOR': StandardScaler(), 'PIB_MEX': StandardScaler(), 'PIB_IDN': StandardScaler(), 'PIB_SAU': StandardScaler(), 'PIB_ZAF': StandardScaler(), 'PIB_TUR': StandardScaler(), 'PIB_ESP': StandardScaler(), 'relative_time_idx': StandardScaler(), 'open': StandardScaler(), 'max': StandardScaler(), 'min': StandardScaler(), 'var': StandardScaler(), 'MACD': StandardScaler(), 'Signal_Line': StandardScaler(), 'target_lag1': StandardScaler(), 'target_lag2': StandardScaler(), 'target_lag3': StandardScaler(), 'target_lag4': StandardScaler(), 'target_lag5': StandardScaler(), 'target_lag6': StandardScaler(), 'target_lag7': StandardScaler(), 'target_lag8': StandardScaler(), 'target_lag9': StandardScaler(), 'target_lag10': StandardScaler(), 'SMA_5': StandardScaler(), 'SMA_10': StandardScaler(), 'SMA_20': StandardScaler(), 'SMA_50': StandardScaler(), 'SMA_100': StandardScaler(), 'SMA_200': StandardScaler(), 'EMA_5': StandardScaler(), 'EMA_10': StandardScaler(), 'EMA_20': StandardScaler(), 'EMA_50': StandardScaler(), 'EMA_100': StandardScaler(), 'EMA_200': StandardScaler(), 'RSI_14': StandardScaler(), 'Bollinger_Upper_20': StandardScaler(), 'Bollinger_Lower_20': StandardScaler(), 'ATR_14': StandardScaler(), 'CCI_10': StandardScaler(), 'CCI_20': StandardScaler(), 'ROC_10': StandardScaler(), 'ROC_14': StandardScaler(), 'ROC_20': StandardScaler(), 'Stochastic_14_K': StandardScaler(), 'Stochastic_14_D': StandardScaler(), 'Williams_%R_14': StandardScaler(), 'VIX': StandardScaler(), 'EUVIX': StandardScaler(), 'exog_syp500': StandardScaler(), 'exog_ibex35': StandardScaler(), 'exog_nasdaq': StandardScaler(), 'exog_eustoxx': StandardScaler(), 'target_smoothed_1': StandardScaler()},\n",
       "\trandomize_length=None,\n",
       "\tpredict_mode=True\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2a24e8",
   "metadata": {},
   "source": [
    "\n",
    "# LEARNIG RATE FINDER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fa807d",
   "metadata": {},
   "source": [
    "En primer lugar realizamos un estudio para hallar de forma aproximada el valor optimo de tasa de aprendizaje.  No es recomendable al 100% usar el valor sugerido directamente pues a veces no encuentra el mejor, sin embargo si que da un muy buen punto de partida por donde empezar a probar. Para ello usamos un modelo TFT cualquiera basico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54055c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if lr_finder:\n",
    "    res = get_best_lr(train, train_dataloader, val_dataloader, **tft_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008a1fdd",
   "metadata": {},
   "source": [
    "# MODELLING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927621bc",
   "metadata": {},
   "source": [
    "## TRAIN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "152ce290",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not grid_search:\n",
    "    # tft_params[\"learning_rate\"] = 0.01\n",
    "    tft, val_loss = tft_trainer(train, train_dataloader, val_dataloader, max_epochs=epochs, **tft_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0f0114",
   "metadata": {},
   "source": [
    "### EVAL MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba6ae28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not grid_search:\n",
    "    preds = tft_predict(tft, val_dataloader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f4ad1d",
   "metadata": {},
   "source": [
    "## GRID SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45763d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combinaci√≥n ya probada, saltando: {'gradient_clip_val': 0.05, 'hidden_size': 32, 'dropout': 0.2, 'hidden_continuous_size': 16, 'attention_head_size': 16, 'learning_rate': 0.005, 'loss': QuantileLoss(quantiles=[0.02, 0.1, 0.25, 0.5, 0.75, 0.9, 0.98]), 'test_len': 125, 'pred_len': 25, 'n_prev_len': 100}\n",
      "\n",
      " -------------------------------------------------------- \n",
      " Probando combinaci√≥n aleatoria 2/100: {'gradient_clip_val': 0.05, 'hidden_size': 16, 'dropout': 0.3, 'hidden_continuous_size': 128, 'attention_head_size': 4, 'learning_rate': 0.03, 'loss': QuantileLoss(quantiles=[0.02, 0.1, 0.25, 0.5, 0.75, 0.9, 0.98]), 'test_len': 125, 'pred_len': 25, 'n_prev_len': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:30<00:00,  1.05it/s, v_num=325, train_loss_step=8.430, val_loss=40.50, train_loss_epoch=9.260]      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:32<00:00,  0.99it/s, v_num=325, train_loss_step=8.430, val_loss=40.50, train_loss_epoch=9.260]\n",
      "Number of parameters in network: 554.4k\n",
      "Training time: 979m 27s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nueva mejor combinaci√≥n encontrada: {'gradient_clip_val': 0.05, 'hidden_size': 16, 'dropout': 0.3, 'hidden_continuous_size': 128, 'attention_head_size': 4, 'learning_rate': 0.03, 'loss': QuantileLoss(quantiles=[0.02, 0.1, 0.25, 0.5, 0.75, 0.9, 0.98]), 'test_len': 125, 'pred_len': 25, 'n_prev_len': 100} con p√©rdida 40.4557\n",
      "\n",
      " -------------------------------------------------------- \n",
      " Probando combinaci√≥n aleatoria 3/100: {'gradient_clip_val': 0.05, 'hidden_size': 8, 'dropout': 0.1, 'hidden_continuous_size': 64, 'attention_head_size': 8, 'learning_rate': 0.01, 'loss': QuantileLoss(quantiles=[0.02, 0.1, 0.25, 0.5, 0.75, 0.9, 0.98]), 'test_len': 125, 'pred_len': 25, 'n_prev_len': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:31<00:00,  1.02it/s, v_num=331, train_loss_step=12.40, val_loss=87.90, train_loss_epoch=16.40]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:32<00:00,  0.99it/s, v_num=331, train_loss_step=12.40, val_loss=87.90, train_loss_epoch=16.40]\n",
      "Number of parameters in network: 151.1k\n",
      "Training time: 25m 46s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------------------------------------------- \n",
      " Probando combinaci√≥n aleatoria 4/100: {'gradient_clip_val': 0.01, 'hidden_size': 8, 'dropout': 0.2, 'hidden_continuous_size': 128, 'attention_head_size': 4, 'learning_rate': 0.005, 'loss': QuantileLoss(quantiles=[0.02, 0.1, 0.25, 0.5, 0.75, 0.9, 0.98]), 'test_len': 125, 'pred_len': 25, 'n_prev_len': 100}\n",
      "Epoch 49: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:32<00:00,  1.00it/s, v_num=337, train_loss_step=25.40, val_loss=131.0, train_loss_epoch=22.90]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:32<00:00,  0.97it/s, v_num=337, train_loss_step=25.40, val_loss=131.0, train_loss_epoch=22.90]\n",
      "Number of parameters in network: 264.5k\n",
      "Training time: 27m 50s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------------------------------------------- \n",
      " Probando combinaci√≥n aleatoria 5/100: {'gradient_clip_val': 0.03, 'hidden_size': 16, 'dropout': 0.2, 'hidden_continuous_size': 128, 'attention_head_size': 4, 'learning_rate': 0.03, 'loss': QuantileLoss(quantiles=[0.02, 0.1, 0.25, 0.5, 0.75, 0.9, 0.98]), 'test_len': 125, 'pred_len': 25, 'n_prev_len': 100}\n",
      "Epoch 49: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:24<00:00,  1.33it/s, v_num=343, train_loss_step=11.10, val_loss=103.0, train_loss_epoch=11.90]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:24<00:00,  1.29it/s, v_num=343, train_loss_step=11.10, val_loss=103.0, train_loss_epoch=11.90]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 554.4k\n",
      "Training time: 22m 4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------------------------------------------- \n",
      " Probando combinaci√≥n aleatoria 6/100: {'gradient_clip_val': 0.05, 'hidden_size': 32, 'dropout': 0.3, 'hidden_continuous_size': 16, 'attention_head_size': 16, 'learning_rate': 0.03, 'loss': QuantileLoss(quantiles=[0.02, 0.1, 0.25, 0.5, 0.75, 0.9, 0.98]), 'test_len': 125, 'pred_len': 25, 'n_prev_len': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:25<00:00,  1.24it/s, v_num=349, train_loss_step=7.900, val_loss=42.30, train_loss_epoch=7.470]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:26<00:00,  1.20it/s, v_num=349, train_loss_step=7.900, val_loss=42.30, train_loss_epoch=7.470]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 317.6k\n",
      "Training time: 23m 6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------------------------------------------- \n",
      " Probando combinaci√≥n aleatoria 7/100: {'gradient_clip_val': 0.05, 'hidden_size': 16, 'dropout': 0.2, 'hidden_continuous_size': 64, 'attention_head_size': 16, 'learning_rate': 0.03, 'loss': QuantileLoss(quantiles=[0.02, 0.1, 0.25, 0.5, 0.75, 0.9, 0.98]), 'test_len': 125, 'pred_len': 25, 'n_prev_len': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:25<00:00,  1.25it/s, v_num=355, train_loss_step=11.70, val_loss=58.00, train_loss_epoch=10.50]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:26<00:00,  1.20it/s, v_num=355, train_loss_step=11.70, val_loss=58.00, train_loss_epoch=10.50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 337.4k\n",
      "Training time: 23m 25s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------------------------------------------- \n",
      " Probando combinaci√≥n aleatoria 8/100: {'gradient_clip_val': 0.05, 'hidden_size': 8, 'dropout': 0.3, 'hidden_continuous_size': 16, 'attention_head_size': 8, 'learning_rate': 0.03, 'loss': QuantileLoss(quantiles=[0.02, 0.1, 0.25, 0.5, 0.75, 0.9, 0.98]), 'test_len': 125, 'pred_len': 25, 'n_prev_len': 100}\n",
      "Epoch 49: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:27<00:00,  1.17it/s, v_num=361, train_loss_step=14.60, val_loss=45.80, train_loss_epoch=12.60]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:28<00:00,  1.14it/s, v_num=361, train_loss_step=14.60, val_loss=45.80, train_loss_epoch=12.60]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 66.1k\n",
      "Training time: 22m 53s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combinaci√≥n ya probada, saltando: {'gradient_clip_val': 0.01, 'hidden_size': 32, 'dropout': 0.1, 'hidden_continuous_size': 128, 'attention_head_size': 16, 'learning_rate': 0.01, 'loss': QuantileLoss(quantiles=[0.02, 0.1, 0.25, 0.5, 0.75, 0.9, 0.98]), 'test_len': 125, 'pred_len': 25, 'n_prev_len': 100}\n",
      "\n",
      " -------------------------------------------------------- \n",
      " Probando combinaci√≥n aleatoria 10/100: {'gradient_clip_val': 0.03, 'hidden_size': 16, 'dropout': 0.1, 'hidden_continuous_size': 128, 'attention_head_size': 16, 'learning_rate': 0.03, 'loss': QuantileLoss(quantiles=[0.02, 0.1, 0.25, 0.5, 0.75, 0.9, 0.98]), 'test_len': 125, 'pred_len': 25, 'n_prev_len': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:29<00:00,  1.08it/s, v_num=367, train_loss_step=7.910, val_loss=9.220, train_loss_epoch=9.740]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:30<00:00,  1.05it/s, v_num=367, train_loss_step=7.910, val_loss=9.220, train_loss_epoch=9.740]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 554.3k\n",
      "Training time: 23m 31s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nueva mejor combinaci√≥n encontrada: {'gradient_clip_val': 0.03, 'hidden_size': 16, 'dropout': 0.1, 'hidden_continuous_size': 128, 'attention_head_size': 16, 'learning_rate': 0.03, 'loss': QuantileLoss(quantiles=[0.02, 0.1, 0.25, 0.5, 0.75, 0.9, 0.98]), 'test_len': 125, 'pred_len': 25, 'n_prev_len': 100} con p√©rdida 9.2243\n",
      "\n",
      " -------------------------------------------------------- \n",
      " Probando combinaci√≥n aleatoria 11/100: {'gradient_clip_val': 0.03, 'hidden_size': 32, 'dropout': 0.2, 'hidden_continuous_size': 16, 'attention_head_size': 8, 'learning_rate': 0.03, 'loss': QuantileLoss(quantiles=[0.02, 0.1, 0.25, 0.5, 0.75, 0.9, 0.98]), 'test_len': 125, 'pred_len': 25, 'n_prev_len': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:27<00:00,  1.17it/s, v_num=373, train_loss_step=8.370, val_loss=26.00, train_loss_epoch=7.420]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:27<00:00,  1.14it/s, v_num=373, train_loss_step=8.370, val_loss=26.00, train_loss_epoch=7.420]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 317.8k\n",
      "Training time: 22m 55s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------------------------------------------- \n",
      " Probando combinaci√≥n aleatoria 12/100: {'gradient_clip_val': 0.01, 'hidden_size': 32, 'dropout': 0.1, 'hidden_continuous_size': 16, 'attention_head_size': 16, 'learning_rate': 0.005, 'loss': QuantileLoss(quantiles=[0.02, 0.1, 0.25, 0.5, 0.75, 0.9, 0.98]), 'test_len': 125, 'pred_len': 25, 'n_prev_len': 100}\n",
      "Epoch 49: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:26<00:00,  1.22it/s, v_num=379, train_loss_step=16.90, val_loss=89.80, train_loss_epoch=16.40]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:26<00:00,  1.19it/s, v_num=379, train_loss_step=16.90, val_loss=89.80, train_loss_epoch=16.40]\n",
      "Number of parameters in network: 317.6k\n",
      "Training time: 23m 23s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------------------------------------------- \n",
      " Probando combinaci√≥n aleatoria 13/100: {'gradient_clip_val': 0.03, 'hidden_size': 16, 'dropout': 0.1, 'hidden_continuous_size': 128, 'attention_head_size': 4, 'learning_rate': 0.005, 'loss': QuantileLoss(quantiles=[0.02, 0.1, 0.25, 0.5, 0.75, 0.9, 0.98]), 'test_len': 125, 'pred_len': 25, 'n_prev_len': 100}\n",
      "Epoch 49: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:26<00:00,  1.22it/s, v_num=385, train_loss_step=16.70, val_loss=64.10, train_loss_epoch=16.70]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:26<00:00,  1.19it/s, v_num=385, train_loss_step=16.70, val_loss=64.10, train_loss_epoch=16.70]\n",
      "Number of parameters in network: 554.4k\n",
      "Training time: 22m 51s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------------------------------------------- \n",
      " Probando combinaci√≥n aleatoria 14/100: {'gradient_clip_val': 0.05, 'hidden_size': 32, 'dropout': 0.1, 'hidden_continuous_size': 64, 'attention_head_size': 16, 'learning_rate': 0.03, 'loss': QuantileLoss(quantiles=[0.02, 0.1, 0.25, 0.5, 0.75, 0.9, 0.98]), 'test_len': 125, 'pred_len': 25, 'n_prev_len': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:25<00:00,  1.26it/s, v_num=391, train_loss_step=5.440, val_loss=93.60, train_loss_epoch=5.740]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:26<00:00,  1.22it/s, v_num=391, train_loss_step=5.440, val_loss=93.60, train_loss_epoch=5.740]\n",
      "Number of parameters in network: 845.1k\n",
      "Training time: 23m 54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------------------------------------------- \n",
      " Probando combinaci√≥n aleatoria 15/100: {'gradient_clip_val': 0.03, 'hidden_size': 16, 'dropout': 0.2, 'hidden_continuous_size': 128, 'attention_head_size': 8, 'learning_rate': 0.01, 'loss': QuantileLoss(quantiles=[0.02, 0.1, 0.25, 0.5, 0.75, 0.9, 0.98]), 'test_len': 125, 'pred_len': 25, 'n_prev_len': 100}\n",
      "Epoch 49: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:25<00:00,  1.24it/s, v_num=397, train_loss_step=16.70, val_loss=96.50, train_loss_epoch=15.90]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:26<00:00,  1.21it/s, v_num=397, train_loss_step=16.70, val_loss=96.50, train_loss_epoch=15.90]\n",
      "Number of parameters in network: 554.3k\n",
      "Training time: 23m 35s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------------------------------------------- \n",
      " Probando combinaci√≥n aleatoria 16/100: {'gradient_clip_val': 0.01, 'hidden_size': 16, 'dropout': 0.3, 'hidden_continuous_size': 128, 'attention_head_size': 4, 'learning_rate': 0.005, 'loss': QuantileLoss(quantiles=[0.02, 0.1, 0.25, 0.5, 0.75, 0.9, 0.98]), 'test_len': 125, 'pred_len': 25, 'n_prev_len': 100}\n",
      "Epoch 49: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:26<00:00,  1.19it/s, v_num=403, train_loss_step=16.80, val_loss=85.80, train_loss_epoch=18.70]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:27<00:00,  1.16it/s, v_num=403, train_loss_step=16.80, val_loss=85.80, train_loss_epoch=18.70]\n",
      "Number of parameters in network: 554.4k\n",
      "Training time: 23m 12s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------------------------------------------- \n",
      " Probando combinaci√≥n aleatoria 17/100: {'gradient_clip_val': 0.01, 'hidden_size': 8, 'dropout': 0.3, 'hidden_continuous_size': 64, 'attention_head_size': 8, 'learning_rate': 0.005, 'loss': QuantileLoss(quantiles=[0.02, 0.1, 0.25, 0.5, 0.75, 0.9, 0.98]), 'test_len': 125, 'pred_len': 25, 'n_prev_len': 100}\n",
      "Epoch 49: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:24<00:00,  1.28it/s, v_num=409, train_loss_step=20.90, val_loss=41.00, train_loss_epoch=20.30]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:25<00:00,  1.25it/s, v_num=409, train_loss_step=20.90, val_loss=41.00, train_loss_epoch=20.30]\n",
      "Number of parameters in network: 151.1k\n",
      "Training time: 23m 31s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------------------------------------------- \n",
      " Probando combinaci√≥n aleatoria 18/100: {'gradient_clip_val': 0.01, 'hidden_size': 8, 'dropout': 0.3, 'hidden_continuous_size': 128, 'attention_head_size': 16, 'learning_rate': 0.03, 'loss': QuantileLoss(quantiles=[0.02, 0.1, 0.25, 0.5, 0.75, 0.9, 0.98]), 'test_len': 125, 'pred_len': 25, 'n_prev_len': 100}\n",
      "Epoch 49: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:25<00:00,  1.23it/s, v_num=415, train_loss_step=13.20, val_loss=39.10, train_loss_epoch=15.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:26<00:00,  1.20it/s, v_num=415, train_loss_step=13.20, val_loss=39.10, train_loss_epoch=15.20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 264.4k\n",
      "Training time: 23m 11s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------------------------------------------- \n",
      " Probando combinaci√≥n aleatoria 19/100: {'gradient_clip_val': 0.03, 'hidden_size': 8, 'dropout': 0.3, 'hidden_continuous_size': 64, 'attention_head_size': 16, 'learning_rate': 0.005, 'loss': QuantileLoss(quantiles=[0.02, 0.1, 0.25, 0.5, 0.75, 0.9, 0.98]), 'test_len': 125, 'pred_len': 25, 'n_prev_len': 100}\n",
      "Epoch 49: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:26<00:00,  1.22it/s, v_num=421, train_loss_step=22.30, val_loss=31.40, train_loss_epoch=20.10]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:27<00:00,  1.18it/s, v_num=421, train_loss_step=22.30, val_loss=31.40, train_loss_epoch=20.10]\n",
      "Number of parameters in network: 151.0k\n",
      "Training time: 24m 4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------------------------------------------- \n",
      " Probando combinaci√≥n aleatoria 20/100: {'gradient_clip_val': 0.03, 'hidden_size': 32, 'dropout': 0.3, 'hidden_continuous_size': 64, 'attention_head_size': 8, 'learning_rate': 0.03, 'loss': QuantileLoss(quantiles=[0.02, 0.1, 0.25, 0.5, 0.75, 0.9, 0.98]), 'test_len': 125, 'pred_len': 25, 'n_prev_len': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:25<00:00,  1.23it/s, v_num=427, train_loss_step=9.000, val_loss=96.60, train_loss_epoch=10.80]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:26<00:00,  1.20it/s, v_num=427, train_loss_step=9.000, val_loss=96.60, train_loss_epoch=10.80]\n",
      "Number of parameters in network: 845.2k\n",
      "Training time: 24m 35s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------------------------------------------- \n",
      " Probando combinaci√≥n aleatoria 21/100: {'gradient_clip_val': 0.05, 'hidden_size': 16, 'dropout': 0.1, 'hidden_continuous_size': 64, 'attention_head_size': 8, 'learning_rate': 0.03, 'loss': QuantileLoss(quantiles=[0.02, 0.1, 0.25, 0.5, 0.75, 0.9, 0.98]), 'test_len': 125, 'pred_len': 25, 'n_prev_len': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:24<00:00,  1.30it/s, v_num=433, train_loss_step=7.970, val_loss=56.00, train_loss_epoch=8.210]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:25<00:00,  1.27it/s, v_num=433, train_loss_step=7.970, val_loss=56.00, train_loss_epoch=8.210]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 337.5k\n",
      "Training time: 23m 25s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------------------------------------------- \n",
      " Probando combinaci√≥n aleatoria 22/100: {'gradient_clip_val': 0.05, 'hidden_size': 32, 'dropout': 0.1, 'hidden_continuous_size': 128, 'attention_head_size': 16, 'learning_rate': 0.005, 'loss': QuantileLoss(quantiles=[0.02, 0.1, 0.25, 0.5, 0.75, 0.9, 0.98]), 'test_len': 125, 'pred_len': 25, 'n_prev_len': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:26<00:00,  1.22it/s, v_num=439, train_loss_step=14.60, val_loss=144.0, train_loss_epoch=14.30]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:26<00:00,  1.19it/s, v_num=439, train_loss_step=14.60, val_loss=144.0, train_loss_epoch=14.30]\n",
      "Number of parameters in network: 1265.4k\n",
      "Training time: 25m 59s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------------------------------------------- \n",
      " Probando combinaci√≥n aleatoria 23/100: {'gradient_clip_val': 0.05, 'hidden_size': 8, 'dropout': 0.2, 'hidden_continuous_size': 64, 'attention_head_size': 4, 'learning_rate': 0.03, 'loss': QuantileLoss(quantiles=[0.02, 0.1, 0.25, 0.5, 0.75, 0.9, 0.98]), 'test_len': 125, 'pred_len': 25, 'n_prev_len': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:31<00:00,  1.02it/s, v_num=445, train_loss_step=13.20, val_loss=91.80, train_loss_epoch=13.60]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:32<00:00,  0.99it/s, v_num=445, train_loss_step=13.20, val_loss=91.80, train_loss_epoch=13.60]\n",
      "Number of parameters in network: 151.1k\n",
      "Training time: 24m 29s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------------------------------------------- \n",
      " Probando combinaci√≥n aleatoria 24/100: {'gradient_clip_val': 0.01, 'hidden_size': 32, 'dropout': 0.3, 'hidden_continuous_size': 16, 'attention_head_size': 16, 'learning_rate': 0.03, 'loss': QuantileLoss(quantiles=[0.02, 0.1, 0.25, 0.5, 0.75, 0.9, 0.98]), 'test_len': 125, 'pred_len': 25, 'n_prev_len': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 26/32 [00:29<00:06,  0.88it/s, v_num=451, train_loss_step=11.30, val_loss=79.90, train_loss_epoch=11.10]      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    }
   ],
   "source": [
    "if grid_search == \"random\":\n",
    "    # Suprime todos los warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    # Llamada a la funci√≥n de b√∫squeda aleatoria\n",
    "    best_model, best_params, best_val_loss = random_hyperparameter_search(\n",
    "        data,\n",
    "        train,\n",
    "        train_dataloader,\n",
    "        val_dataloader,\n",
    "        test,\n",
    "        param_grid,\n",
    "        n_iterations=100,\n",
    "        max_epochs=50,\n",
    "        save_dir=f'./plots/gauss_multiexog_syp500_-{n_prev_len}d-{date_start.replace(\"-\",\"\")}-{date_end.replace(\"-\",\"\")}-lessFilters',\n",
    "        csv_file=f\"./results/gauss_multiexog_syp500_-{n_prev_len}d-{date_start}-{date_end}.csv\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e9473e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if grid_search == \"exhaustive\":\n",
    "    \n",
    "    # Suprime todos los warnings \n",
    "\n",
    "    \n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "    # Llamada a la funci√≥n de b√∫squeda de hiperpar√°metros\n",
    "    best_model, best_params, best_val_loss = exhaustive_hyperparameter_search(\n",
    "        data, train, train_dataloader, val_dataloader, test, param_grid, max_epochs=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebd5b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if grid_search:\n",
    "    tft_predict(best_model, val_dataloader, n_preds=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f03dd31",
   "metadata": {},
   "source": [
    "# TEST EVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3272e531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_preds(\n",
    "    train,\n",
    "    test,\n",
    "    model,\n",
    "    encoder_lenght,\n",
    "    test_lenght,\n",
    "    pred_lenght,\n",
    "    quantiles: bool = True,\n",
    "):\n",
    "    # group = model.output_transformer.groups[0]\n",
    "    if quantiles:\n",
    "        try:  # for Quantileloss\n",
    "            preds = []\n",
    "            preds_data = pd.concat([train[-encoder_lenght:], test])\n",
    "            for i in range(0, test_lenght, pred_lenght):\n",
    "                new_data = preds_data[i : i + encoder_lenght + pred_lenght]\n",
    "                new_data.loc[:, group] = new_data.iloc[0, new_data.columns.get_loc(group)]\n",
    "                new_raw_predictions = model.predict(new_data, mode=\"raw\", return_x=True)\n",
    "                prediction = []\n",
    "                for i in range(pred_lenght):\n",
    "                    prediction.append(float(new_raw_predictions.output.prediction[0][i][3]))\n",
    "                preds.append(prediction)\n",
    "        except:  # for MQF2DistributionLoss\n",
    "            preds = []\n",
    "            preds_data = pd.concat([train[-encoder_lenght:], test])\n",
    "            for i in range(0, test_lenght, pred_lenght):\n",
    "                new_data = preds_data[i : i + encoder_lenght + pred_lenght]\n",
    "                new_data.loc[:, group] = new_data.iloc[0, new_data.columns.get_loc(group)]\n",
    "                prediction = model.to_prediction(new_raw_predictions.output)[0].flatten().tolist()\n",
    "                preds.append(prediction)\n",
    "    else:\n",
    "        preds = []\n",
    "        preds_data = pd.concat([train[-encoder_lenght:], test])\n",
    "        for i in range(0, test_lenght, pred_lenght):\n",
    "            new_data = preds_data[i : i + encoder_lenght + pred_lenght]\n",
    "            new_data.loc[:, group] = new_data.iloc[0, new_data.columns.get_loc(group)]\n",
    "            new_raw_predictions = model.predict(new_data, mode=\"raw\", return_x=True)\n",
    "            prediction = new_raw_predictions.output.prediction[0].flatten().tolist()\n",
    "            preds.append(prediction)\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed3276c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = []\n",
    "# preds_data = pd.concat([data[-n_prev_len:], test])\n",
    "# # preds_data = preds_data.ffill()\n",
    "# preds_data[\"target\"] = float(1)\n",
    "# # preds_data.drop(columns=[\"target\"], inplace=True)\n",
    "# for i in range(0, test_len, pred_len):\n",
    "#     new_data = preds_data[i : i + n_prev_len + pred_len]\n",
    "#     new_data.loc[:, group] = new_data.iloc[0, new_data.columns.get_loc(group)]\n",
    "#     new_raw_predictions = tft.predict(new_data, mode=\"raw\", return_x=True)\n",
    "#     prediction = new_raw_predictions.output.prediction[0].flatten().tolist()\n",
    "#     preds.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a408112",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = make_preds(\n",
    "    train=data,\n",
    "    test=test,\n",
    "    model=tft,\n",
    "    encoder_lenght=n_prev_len,\n",
    "    test_lenght=test_len,\n",
    "    pred_lenght=pred_len,\n",
    "    quantiles=True if isinstance(loss, QuantileLoss) else False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9847a87",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mThe kernel died. Error: ... View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, root_mean_squared_error\n",
    "\n",
    "dates = test[\"Date\"].to_list()\n",
    "preds_flat = [item for sublist in preds for item in sublist]\n",
    "\n",
    "# real_vals = list(data[-n_preds * pred_len :][\"target\"])\n",
    "real_vals = test[\"target\"].to_list()\n",
    "\n",
    "print(f\"MAE: {mean_absolute_error(real_vals, preds_flat)}\")\n",
    "print(f\"MAPE: {mean_absolute_percentage_error(real_vals, preds_flat)}\")\n",
    "print(f\"RMSE: {root_mean_squared_error(real_vals, preds_flat)}\")\n",
    "\n",
    "plt.plot(dates, preds_flat, color=\"r\")\n",
    "plt.plot(dates, real_vals, color=\"g\")\n",
    "plt.title(\"Real vs Preds\")\n",
    "plt.xlabel(\"√çndice\")\n",
    "plt.ylabel(\"Valor\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b460c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mThe kernel died. Error: ... View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, mean_squared_error\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# Convertir las fechas a formato de datetime si no est√°n ya\n",
    "dates = pd.to_datetime(test[\"Date\"]).to_list()\n",
    "\n",
    "# Aplanar las predicciones si es necesario\n",
    "preds_flat = [item for sublist in preds for item in sublist]\n",
    "\n",
    "# Valores reales\n",
    "real_vals = test[\"target\"].to_list()\n",
    "\n",
    "# M√©tricas de error\n",
    "print(f\"MAE: {mean_absolute_error(real_vals, preds_flat)}\")\n",
    "print(f\"MAPE: {mean_absolute_percentage_error(real_vals, preds_flat)}\")\n",
    "print(f\"RMSE: {mean_squared_error(real_vals, preds_flat, squared=False)}\")\n",
    "\n",
    "# Gr√°fico\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(dates, real_vals, color=\"g\", label=\"Valores Reales\")\n",
    "plt.plot(dates, preds_flat, color=\"r\", label=\"Predicciones\")\n",
    "plt.title(\"Valores Reales vs Predicciones\")\n",
    "plt.xlabel(\"Fecha\")\n",
    "plt.ylabel(\"Valor (‚Ç¨)\")\n",
    "\n",
    "# Formato de fecha en el eje x\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter(\"%Y-%m-%d\"))\n",
    "plt.gca().xaxis.set_major_locator(mdates.AutoDateLocator())\n",
    "plt.gcf().autofmt_xdate()  # Rotar fechas para mejor visualizaci√≥n\n",
    "\n",
    "# A√±adir leyenda\n",
    "plt.legend()\n",
    "\n",
    "# Mostrar gr√°fico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f373476",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mThe kernel died. Error: ... View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# Supongamos que `preds`, `test`, y `dates` ya est√°n definidos en tu entorno\n",
    "\n",
    "# Aplanar la lista de predicciones\n",
    "preds_flat = [item for sublist in preds for item in sublist]\n",
    "\n",
    "# Convertir los valores reales a una lista\n",
    "real_vals = test[\"target\"].to_list()\n",
    "\n",
    "# Lista de fechas (timestamps)\n",
    "\n",
    "\n",
    "# Calcular el error absoluto medio\n",
    "print(f\"MAE: {mean_absolute_error(real_vals, preds_flat)}\")\n",
    "print(f\"MAPE: {mean_absolute_percentage_error(real_vals, preds_flat)}\")\n",
    "print(f\"RMSE: {root_mean_squared_error(real_vals, preds_flat)}\")\n",
    "# Crear la gr√°fica\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(dates, preds_flat, color=\"r\", label=\"Predicciones\", marker=\"o\", linestyle=\"--\")\n",
    "plt.plot(dates, real_vals, color=\"g\", label=\"Valores Reales\", marker=\"x\", linestyle=\"-\")\n",
    "\n",
    "# A√±adir t√≠tulo y etiquetas\n",
    "plt.title(\"Predicciones vs Valores Reales\")\n",
    "plt.xlabel(\"Fecha\")\n",
    "plt.ylabel(\"Valor\")\n",
    "\n",
    "# Formatear las fechas en el eje x\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter(\"%Y-%m-%d\"))\n",
    "# plt.gca().xaxis.set_major_locator(mdates.HourLocator(interval=6))\n",
    "plt.gcf().autofmt_xdate()  # Rotar las etiquetas de fecha\n",
    "\n",
    "# A√±adir cuadr√≠cula y leyenda\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# Mostrar la gr√°fica\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081d3ac6",
   "metadata": {},
   "source": [
    "# INFERENCE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584a21f5",
   "metadata": {},
   "source": [
    "## Retrain for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d680c22",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mThe kernel died. Error: ... View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "features = [\n",
    "    col for col in data.columns if col != \"target\"\n",
    "]  # Columnas de caracter√≠sticas and col != \"Date\"\n",
    "\n",
    "max_prediction_length = pred_len\n",
    "max_encoder_length = n_prev_len  # 48\n",
    "# training_cutoff = data[\"Date\"].max() - pd.Timedelta(hours=max_encoder_length)\n",
    "training_cutoff = data[\"time_idx\"].max() - max_prediction_length\n",
    "\n",
    "retrain = TimeSeriesDataSet(\n",
    "    full.dropna()[lambda x: x.time_idx <= training_cutoff],\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"target\",\n",
    "    group_ids=[group],\n",
    "    min_encoder_length=max_encoder_length,  # keep encoder length long (as it is in the validation set)\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    # min_prediction_length=24,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    static_categoricals=[],\n",
    "    static_reals=[],\n",
    "    time_varying_known_categoricals=[],  # group of categorical variables can be treated as one variable\n",
    "    time_varying_known_reals=[\"Date\", \"month\", \"week\", \"day\", \"time_idx\"],\n",
    "    time_varying_unknown_categoricals=[],\n",
    "    time_varying_unknown_reals=[\n",
    "        \"target\",\n",
    "        \"open\",\n",
    "        \"max\",\n",
    "        \"min\",\n",
    "        \"vol\",\n",
    "        \"var\",\n",
    "        \"SMA_5\",\n",
    "        \"EMA_5\",\n",
    "        \"SMA_10\",\n",
    "        \"EMA_10\",\n",
    "        \"SMA_15\",\n",
    "        \"EMA_15\",\n",
    "        \"SMA_20\",\n",
    "        \"EMA_20\",\n",
    "        \"RSI_6\",\n",
    "        \"RSI_10\",\n",
    "        \"RSI_14\",\n",
    "        \"Bollinger_Upper_5\",\n",
    "        \"Bollinger_Lower_5\",\n",
    "        \"Bollinger_Upper_10\",\n",
    "        \"Bollinger_Lower_10\",\n",
    "        \"Bollinger_Upper_15\",\n",
    "        \"Bollinger_Lower_15\",\n",
    "        \"Bollinger_Upper_20\",\n",
    "        \"Bollinger_Lower_20\",\n",
    "        \"MACD\",\n",
    "        \"Signal_Line\",\n",
    "        \"ATR_5\",\n",
    "        \"ATR_10\",\n",
    "        \"ATR_15\",\n",
    "        \"ATR_20\",\n",
    "        \"CCI_5\",\n",
    "        \"CCI_10\",\n",
    "        \"CCI_15\",\n",
    "        \"CCI_20\",\n",
    "        \"ROC_10\",\n",
    "        \"ROC_14\",\n",
    "        \"ROC_20\",\n",
    "        \"ROC_50\",\n",
    "        \"Stochastic_10_K\",\n",
    "        \"Stochastic_10_D\",\n",
    "        \"Stochastic_14_K\",\n",
    "        \"Stochastic_14_D\",\n",
    "        \"Stochastic_20_K\",\n",
    "        \"Stochastic_20_D\",\n",
    "        \"Stochastic_25_K\",\n",
    "        \"Stochastic_25_D\",\n",
    "        \"Stochastic_50_K\",\n",
    "        \"Stochastic_50_D\",\n",
    "        \"Williams_%R_10\",\n",
    "        \"Williams_%R_14\",\n",
    "    ],\n",
    "    # lags={\"target\": list(range(1, 5))},\n",
    "    # target_normalizer=GroupNormalizer(\"standard\", groups=[group], transformation=\"softplus\"),\n",
    "    # use softplus and normalize by group\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    allow_missing_timesteps=True,\n",
    "    # add_encoder_length=True,\n",
    "    # categorical_encoders={\n",
    "    #     \"month\": pytorch_forecasting.data.encoders.NaNLabelEncoder(add_nan=True),\n",
    "    #     \"week\": pytorch_forecasting.data.encoders.NaNLabelEncoder(add_nan=True),\n",
    "    #     \"day\": pytorch_forecasting.data.encoders.NaNLabelEncoder(add_nan=True),\n",
    "    # },\n",
    ")\n",
    "\n",
    "revalidation = TimeSeriesDataSet.from_dataset(retrain, full.dropna(), predict=True, stop_randomization=True)\n",
    "\n",
    "# test = TimeSeriesDataSet.from_dataset(training, test_data, predict=True, stop_randomization=True)\n",
    "\n",
    "\n",
    "# create dataloaders for model\n",
    "\n",
    "batch_size = 64  # set this between 32 to 128\n",
    "\n",
    "retrain_dataloader = retrain.to_dataloader(\n",
    "\n",
    "    train=True, batch_size=batch_size, num_workers=7, persistent_workers=True\n",
    "\n",
    ")\n",
    "\n",
    "reval_dataloader = revalidation.to_dataloader(\n",
    "\n",
    "    train=False, batch_size=batch_size, num_workers=7, persistent_workers=True\n",
    "\n",
    ")\n",
    "\n",
    "# test_dataloader = test.to_dataloader(train=False, batch_size=batch_size, num_workers=11, persistent_workers=True)\n",
    "\n",
    "if not grid_search:\n",
    "\n",
    "    # tft_params[\"learning_rate\"] = 0.01\n",
    "\n",
    "    retft, val_loss = tft_trainer(\n",
    "\n",
    "        retrain, retrain_dataloader, reval_dataloader, max_epochs=epochs, **tft_params\n",
    "\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c3c38f",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mThe kernel died. Error: ... View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "encoder_data = full[-n_prev_len:]\n",
    "last_row = full.iloc[-1]\n",
    "# Creamos nuevas filas\n",
    "new_rows = []\n",
    "for i in range(1, 6):\n",
    "    new_row = last_row.copy()\n",
    "    new_row[\"Date\"] += timedelta(days=i)\n",
    "    new_row[\"day\"] += i\n",
    "    new_row[\"time_idx\"] += i\n",
    "    new_rows.append(new_row)\n",
    "\n",
    "# Concatenamos las nuevas filas al DataFrame original\n",
    "decoder_data = pd.DataFrame(new_rows)\n",
    "\n",
    "new_data = pd.concat([encoder_data, decoder_data], ignore_index=True)\n",
    "new_data.loc[:, group] = new_data.iloc[0, new_data.columns.get_loc(group)]\n",
    "# new_data.loc[-pred_len: ,\"target\"] = 1\n",
    "new_raw_predictions = retft.predict(new_data, mode=\"raw\", return_x=True)\n",
    "if isinstance(loss, QuantileLoss):\n",
    "    prediction = []\n",
    "    for i in range(pred_len):\n",
    "        prediction.append(float(new_raw_predictions.output.prediction[0][i][3]))\n",
    "else:\n",
    "    prediction = new_raw_predictions.output.prediction[0].flatten().tolist()\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162b0a6e",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mThe kernel died. Error: ... View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# prediction = [11233.22265625, 11129.837890625, 11228.3486328125, 11315.59375, 11555.85546875]\n",
    "last_vals = full[-10:]\n",
    "last_vals = last_vals[[\"Date\", \"target\"]]\n",
    "fechas_azul = pd.date_range(start=\"2024-08-26\", periods=len(prediction))\n",
    "predictions = pd.DataFrame({\"Date\": fechas_azul, \"target\": prediction})\n",
    "\n",
    "plt.plot(predictions[\"Date\"], predictions[\"target\"], color=\"r\")\n",
    "plt.plot(last_vals[\"Date\"], last_vals[\"target\"], color=\"g\")\n",
    "plt.title(\"Gr√°fica de la lista aplanada\")\n",
    "plt.xlabel(\"√çndice\")\n",
    "plt.ylabel(\"Valor\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88078c66",
   "metadata": {},
   "source": [
    "# INTERPRETABILITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2461fd42",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mThe kernel died. Error: ... View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "interpretation = tft.interpret_output(preds.output, reduction=\"sum\") #\n",
    "tft.plot_interpretation(interpretation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2735f9d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mThe kernel died. Error: ... View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
